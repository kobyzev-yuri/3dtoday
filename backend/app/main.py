"""
FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ 3dtoday
"""

import os
import logging
from pathlib import Path
from typing import Optional, List, Dict, Any
from fastapi import FastAPI, HTTPException, UploadFile, File, Body
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.encoders import jsonable_encoder
import json
from dotenv import load_dotenv

# –ò–º–ø–æ—Ä—Ç –º–æ–¥–µ–ª–µ–π (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å)
try:
    from app.models.schemas import (
        ArticleInput,
        DiagnosticRequest,
        DiagnosticResponse,
        ValidationResponse,
        ClarificationQuestion
    )
except ImportError:
    # Fallback –¥–ª—è –ø—Ä—è–º–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).resolve().parent))
    from models.schemas import (
        ArticleInput,
        DiagnosticRequest,
        DiagnosticResponse,
        ValidationResponse,
        ClarificationQuestion
    )

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
load_dotenv(dotenv_path=Path(__file__).resolve().parents[2] / "config.env")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å –∑–∞–ø–∏—Å—å—é –≤ —Ñ–∞–π–ª
try:
    from app.utils.logger_config import get_api_logger
    logger = get_api_logger()
except ImportError:
    # Fallback –µ—Å–ª–∏ logger_config –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s"
    )
    logger = logging.getLogger(__name__)

# –ö–∞—Å—Ç–æ–º–Ω—ã–π JSON encoder –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ Unicode
class UnicodeJSONResponse(JSONResponse):
    def render(self, content: Any) -> bytes:
        return json.dumps(
            content,
            ensure_ascii=False,
            allow_nan=False,
            indent=None,
            separators=(",", ":"),
        ).encode("utf-8")


# –°–æ–∑–¥–∞–Ω–∏–µ FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
app = FastAPI(
    title="3dtoday Diagnostic API",
    description="API –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø—Ä–æ–±–ª–µ–º 3D-–ø–µ—á–∞—Ç–∏ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π",
    version="0.1.0"
)

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º UnicodeJSONResponse –∫–∞–∫ –∫–ª–∞—Å—Å –æ—Ç–≤–µ—Ç–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
app.router.default_response_class = UnicodeJSONResponse

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í production –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# –ú–æ–¥–µ–ª–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –∏–∑ models.schemas


# ========== –ò–ú–ü–û–†–¢–´ –°–ï–†–í–ò–°–û–í ==========

try:
    import sys
    from pathlib import Path
    # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
    sys.path.insert(0, str(Path(__file__).resolve().parent))
    
    from services.article_indexer import get_article_indexer
    from services.rag_service import get_rag_service
    from services.llm_client import get_llm_client
    from tools.article_collector import ArticleCollector
except ImportError as e:
    logger.error(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ —Å–µ—Ä–≤–∏—Å–æ–≤: {e}")
    # Fallback –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    get_article_indexer = None
    get_rag_service = None
    get_llm_client = None
    ArticleCollector = None


# ========== ENDPOINTS –î–õ–Ø –ê–î–ú–ò–ù–ò–°–¢–†–ê–¢–û–†–û–í ==========

@app.post("/api/kb/articles/parse_with_llm", response_class=UnicodeJSONResponse)
async def parse_url_with_llm(
    request: Optional[Dict[str, Any]] = Body(None),
    url: Optional[str] = Body(None),
    llm_provider: Optional[str] = Body(None),
    model: Optional[str] = Body(None)
):
    """
    –ü–∞—Ä—Å–∏–Ω–≥ URL –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ LLM (GPT-4o –∏–ª–∏ Gemini 3)
    LLM —Å–∞–º –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç JSON –¥–ª—è KB
    
    Body: {
        "url": "URL –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞",
        "llm_provider": "openai|gemini" (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ),
        "model": "–Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏" (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    }
    
    –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
    - LLM —Å–∞–º –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    - –ë–æ–ª–µ–µ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    - –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ JSON –¥–ª—è KB
    """
    try:
        if request:
            url = url or request.get("url")
            llm_provider = llm_provider or request.get("llm_provider", "openai")
            model = model or request.get("model")
        else:
            url = url
            llm_provider = llm_provider or "openai"
        
        if not url:
            raise HTTPException(status_code=400, detail="url –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω")
        
        if llm_provider not in ["openai", "gemini"]:
            raise HTTPException(status_code=400, detail="llm_provider –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 'openai' –∏–ª–∏ 'gemini'")
        
        from services.llm_url_analyzer import LLMURLAnalyzer
        
        analyzer = LLMURLAnalyzer(llm_provider=llm_provider, model=model)
        result = await analyzer.analyze_url(url)
        
        if not result:
            raise HTTPException(status_code=500, detail="–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å URL —á–µ—Ä–µ–∑ LLM")
        
        return {
            "success": True,
            "method": "llm_direct",
            "llm_provider": llm_provider,
            "model": analyzer.model,
            "parsed_document": result
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ URL —á–µ—Ä–µ–∑ LLM: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/kb/articles/parse")
async def parse_document(
    request: Optional[Dict[str, Any]] = Body(None),
    source: Optional[str] = Body(None),
    source_type: Optional[str] = Body(None),
    llm_provider: Optional[str] = Body(None),
    model: Optional[str] = Body(None),
    timeout: Optional[int] = Body(None),
    max_pages: Optional[int] = Body(None)
):
    """
    –ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –∞–≥–µ–Ω—Ç–∞-–±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—è
    
    Body: {
        "source": "URL –∏–ª–∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É, –∏–ª–∏ JSON —Å—Ç—Ä–æ–∫–∞",
        "source_type": "auto|html|pdf|json|url" (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ),
        "llm_provider": "openai|ollama|gemini" (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ),
        "model": "–Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏" (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ),
        "timeout": 180 (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, —Å–µ–∫—É–Ω–¥—ã),
        "max_pages": 30 (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è PDF, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 30 –¥–ª—è Gemini)
    }
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - HTML/URL: —Å—Ç–∞—Ç—å–∏ —Å —Å–∞–π—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 3dtoday.ru)
    - PDF: –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è, –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
    - JSON: –∏–º–ø–æ—Ä—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –±–ª–æ–∫–æ–≤ KB –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    
    –¢–∏–ø—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞:
    - article: —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º 3D-–ø–µ—á–∞—Ç–∏
    - documentation: –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
    - comparison: —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤/–ø—Ä–∏–Ω—Ç–µ—Ä–æ–≤
    - technical: —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
    """
    try:
        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ (request –∫–∞–∫ dict) –∏ –Ω–æ–≤–æ–≥–æ (–æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
        if request:
            source = source or request.get("source") or request.get("url")
            source_type = source_type or request.get("source_type")
            llm_provider = llm_provider or request.get("llm_provider")
            model = model or request.get("model")
            timeout = timeout or request.get("timeout")
            max_pages = max_pages or request.get("max_pages")
        
        if not source:
            raise HTTPException(status_code=400, detail="source –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º source_type –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω
        if not source_type:
            if source.lower().endswith('.pdf'):
                source_type = "pdf"
            elif source.startswith('http://') or source.startswith('https://'):
                source_type = "url"
            else:
                source_type = "json"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        # –î–ª—è PDF –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º Gemini (–ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏)
        if not llm_provider and source_type == "pdf":
            llm_provider = "gemini"
            logger.info(f"üìÑ –î–ª—è PDF –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Gemini –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–ª—É—á—à–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)")
        
        # –î–ª—è Gemini –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º PDF –¥–æ 30 —Å—Ç—Ä–∞–Ω–∏—Ü
        if max_pages is None and llm_provider == "gemini" and source_type == "pdf":
            max_pages = 30
            logger.info(f"üìÑ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ PDF –¥–æ {max_pages} —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è Gemini")
        
        # –í—Ä–µ–º–µ–Ω–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –∏ –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã
        original_provider = None
        original_model = None
        
        if llm_provider:
            original_provider = os.getenv("LLM_PROVIDER")
            os.environ["LLM_PROVIDER"] = llm_provider
        
        if model:
            if llm_provider == "openai":
                original_model = os.getenv("OPENAI_MODEL")
                os.environ["OPENAI_MODEL"] = model
            elif llm_provider == "ollama":
                original_model = os.getenv("OLLAMA_MODEL")
                os.environ["OLLAMA_MODEL"] = model
            elif llm_provider == "gemini":
                original_model = os.getenv("GEMINI_MODEL")
                os.environ["GEMINI_MODEL"] = model
        
        if timeout:
            os.environ["MCP_SERVER_TIMEOUT"] = str(timeout)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        from services.document_parser import DocumentParser
        from agents.kb_librarian import KBLibrarianAgent
        
        logger.info(f"üì• –ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: source_type={source_type}, llm_provider={llm_provider}, max_pages={max_pages}")
        
        parser = DocumentParser()
        doc_data = await parser.parse_document(source, source_type, max_pages=max_pages)
        
        if not doc_data:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç: {source[:100]}")
            raise HTTPException(status_code=404, detail="–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç")
        
        logger.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω: title={doc_data.get('title', 'N/A')[:50]}, content_length={len(doc_data.get('content', ''))}, images_count={len(doc_data.get('images', []))}")
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–π KB
        images = doc_data.get("images", [])
        if images:
            logger.info(f"üì∑ –ù–∞–π–¥–µ–Ω–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ")
            # –ê–≥–µ–Ω—Ç-–±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å –ø—Ä–æ–≤–µ—Ä–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ
            # –ü–æ–∫–∞ –ø–µ—Ä–µ–¥–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –≤ review_and_decide
        
        # –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª: –∞–Ω–∞–ª–∏–∑ + —Ä–µ—à–µ–Ω–∏–µ –æ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ –∞–≥–µ–Ω—Ç–∞-–±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—è
        # –ü–µ—Ä–µ–¥–∞–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä –∏ –º–æ–¥–µ–ª—å –≤ –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        logger.info(f"ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞-–±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—è: llm_provider={llm_provider}, model={model}, timeout={timeout}")
        
        try:
            librarian = KBLibrarianAgent(llm_provider=llm_provider, model=model, timeout=timeout)
            logger.info(f"üìã –ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞ —á–µ—Ä–µ–∑ –∞–≥–µ–Ω—Ç–∞-–±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—è...")
            review_result = await librarian.review_and_decide(
                title=doc_data["title"],
                content=doc_data["content"],
                images=images,  # –ü–µ—Ä–µ–¥–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                url=doc_data.get("url"),
                content_type=doc_data.get("content_type"),
                is_questions_list=doc_data.get("is_questions_list", False)
            )
            logger.info(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: relevance_score={review_result.get('relevance_score', 'N/A')}")
            
            # –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, –ø–æ–º–µ—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–∞–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ
            if review_result.get("is_relevant", False) and images:
                logger.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±—É–¥—É—Ç –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω—ã –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—É—é KB")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —á–µ—Ä–µ–∑ –∞–≥–µ–Ω—Ç–∞-–±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—è: {e}", exc_info=True)
            raise
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        if original_provider:
            os.environ["LLM_PROVIDER"] = original_provider
        if original_model:
            if llm_provider == "openai":
                os.environ["OPENAI_MODEL"] = original_model
            elif llm_provider == "ollama":
                os.environ["OLLAMA_MODEL"] = original_model
            elif llm_provider == "gemini":
                os.environ["GEMINI_MODEL"] = original_model
        
        return {
            "success": True,
            "parsed_document": doc_data,
            "review": review_result
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/kb/articles/validate", response_model=ValidationResponse)
async def validate_article(article: ArticleInput):
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Å—Ç–∞—Ç—å–∏ –ø–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –≤ KB
    """
    try:
        if ArticleCollector is None:
            raise HTTPException(status_code=503, detail="ArticleCollector –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        collector = ArticleCollector()
        
        validation = await collector.validate_article_relevance(
            title=article.title,
            content=article.content,
            url=article.url
        )
        
        metadata = None
        if validation.get("is_relevant", False):
            metadata = await collector.extract_metadata(article.title, article.content)
        
        return ValidationResponse(
            is_relevant=validation.get("is_relevant", False),
            relevance_score=validation.get("relevance_score", 0.0),
            quality_score=validation.get("quality_score", 0.0),
            has_solutions=validation.get("has_solutions", False),
            issues=validation.get("issues", []),
            recommendations=validation.get("recommendations", []),
            metadata=metadata
        )
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å—Ç–∞—Ç—å–∏: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/kb/articles/add_from_parse", response_class=UnicodeJSONResponse)
async def add_article_from_parse(request: Dict[str, Any] = Body(...)):
    """
    –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –≤ KB –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å —É—á–µ—Ç–æ–º —Ä–µ—à–µ–Ω–∏—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
    """
    try:
        if get_article_indexer is None:
            raise HTTPException(status_code=503, detail="ArticleIndexer –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        parsed_document = request.get("parsed_document", {})
        review = request.get("review", {})
        admin_decision = request.get("admin_decision", "needs_review")
        relevance_threshold = request.get("relevance_threshold", 0.6)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ—à–µ–Ω–∏—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
        if admin_decision != "approve":
            raise HTTPException(
                status_code=400,
                detail=f"–°—Ç–∞—Ç—å—è –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∞: —Ä–µ—à–µ–Ω–∏–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ - {admin_decision}"
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø–æ—Ä–æ–≥–∞
        relevance_score = review.get("relevance_score", 0.0)
        if relevance_score < relevance_threshold:
            raise HTTPException(
                status_code=400,
                detail=(
                    f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å ({relevance_score:.2f}) –Ω–∏–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞ "
                    f"({relevance_threshold:.2f}). –°—Ç–∞—Ç—å—è –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏."
                )
            )
        
        indexer = get_article_indexer()
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç—å–∏ –∏–∑ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        title = parsed_document.get("title", "")
        content = parsed_document.get("content", "")
        url = parsed_document.get("url", "")
        section = parsed_document.get("section", "unknown")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è article_id
        article_id = f"{section}_{abs(hash(title)) % 10000}"
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ review
        summary = review.get("summary", {})
        content_type = summary.get("content_type", "article") if summary else parsed_document.get("content_type", "article")
        
        article_data = {
            "article_id": article_id,
            "title": title,
            "content": content,
            "url": url,
            "section": section,
            "date": parsed_document.get("date", ""),
            "relevance_score": relevance_score,
            "quality_score": review.get("quality_score", 0.0),
            "content_type": content_type,
            "problem": summary.get("problem", "") if summary else "",
            "symptoms": summary.get("symptoms", []) if summary else [],
            "solutions": summary.get("solutions", []) if summary else [],
            "printer_models": summary.get("printer_models", []) if summary else [],
            "materials": summary.get("materials", []) if summary else [],
            "abstract": review.get("abstract", ""),
            "admin_decision": admin_decision,
            "librarian_decision": review.get("decision", "needs_review"),
            "relevance_threshold_used": relevance_threshold
        }
        
        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏
        result = await indexer.index_article(article_data)
        
        if result["success"]:
            # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –µ—Å–ª–∏ –µ—Å—Ç—å
            images = parsed_document.get("images", [])
            if images:
                for img_url in images[:5]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                    try:
                        await indexer.index_image(
                            image_url=img_url,
                            article_id=article_id,
                            title=title
                        )
                    except Exception as e:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {img_url}: {e}")
            
            return {
                "success": True,
                "article_id": article_id,
                "message": "–°—Ç–∞—Ç—å—è —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ KB",
                "relevance_score": relevance_score,
                "relevance_threshold": relevance_threshold,
                "admin_decision": admin_decision
            }
        else:
            raise HTTPException(status_code=500, detail=result.get("error", "–û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"))
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏ –∏–∑ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/kb/articles/add_from_parse", response_class=UnicodeJSONResponse)
async def add_article_from_parse(request: Dict[str, Any] = Body(...)):
    """
    –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –≤ KB –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å —É—á–µ—Ç–æ–º —Ä–µ—à–µ–Ω–∏—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
    """
    try:
        if get_article_indexer is None:
            raise HTTPException(status_code=503, detail="ArticleIndexer –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        parsed_document = request.get("parsed_document", {})
        review = request.get("review", {})
        admin_decision = request.get("admin_decision", "needs_review")
        relevance_threshold = request.get("relevance_threshold", 0.6)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ—à–µ–Ω–∏—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
        if admin_decision != "approve":
            raise HTTPException(
                status_code=400,
                detail=f"–°—Ç–∞—Ç—å—è –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∞: —Ä–µ—à–µ–Ω–∏–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ - {admin_decision}"
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø–æ—Ä–æ–≥–∞
        relevance_score = review.get("relevance_score", 0.0)
        if relevance_score < relevance_threshold:
            raise HTTPException(
                status_code=400,
                detail=(
                    f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å ({relevance_score:.2f}) –Ω–∏–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞ "
                    f"({relevance_threshold:.2f}). –°—Ç–∞—Ç—å—è –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏."
                )
            )
        
        indexer = get_article_indexer()
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç—å–∏ –∏–∑ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        title = parsed_document.get("title", "")
        content = parsed_document.get("content", "")
        url = parsed_document.get("url", "")
        section = parsed_document.get("section", "unknown")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è article_id
        article_id = f"{section}_{abs(hash(title)) % 10000}"
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ review
        summary = review.get("summary", {})
        content_type = summary.get("content_type", "article") if summary else parsed_document.get("content_type", "article")
        
        article_data = {
            "article_id": article_id,
            "title": title,
            "content": content,
            "url": url,
            "section": section,
            "date": parsed_document.get("date", ""),
            "relevance_score": relevance_score,
            "quality_score": review.get("quality_score", 0.0),
            "content_type": content_type,
            "problem": summary.get("problem", "") if summary else "",
            "symptoms": summary.get("symptoms", []) if summary else [],
            "solutions": summary.get("solutions", []) if summary else [],
            "printer_models": summary.get("printer_models", []) if summary else [],
            "materials": summary.get("materials", []) if summary else [],
            "abstract": review.get("abstract", ""),
            "admin_decision": admin_decision,
            "librarian_decision": review.get("decision", "needs_review"),
            "relevance_threshold_used": relevance_threshold
        }
        
        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏
        result = await indexer.index_article(article_data)
        
        if result["success"]:
            # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –µ—Å–ª–∏ –µ—Å—Ç—å
            images = parsed_document.get("images", [])
            if images:
                for img_url in images[:5]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                    try:
                        if isinstance(img_url, dict):
                            img_url_str = img_url.get("url", "")
                        else:
                            img_url_str = str(img_url)
                        if img_url_str:
                            await indexer.index_image(
                                image_url=img_url_str,
                                article_id=article_id,
                                title=title
                            )
                    except Exception as e:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {img_url}: {e}")
            
            return {
                "success": True,
                "article_id": article_id,
                "message": "–°—Ç–∞—Ç—å—è —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ KB",
                "relevance_score": relevance_score,
                "relevance_threshold": relevance_threshold,
                "admin_decision": admin_decision
            }
        else:
            raise HTTPException(status_code=500, detail=result.get("error", "–û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"))
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏ –∏–∑ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/kb/articles/add")
async def add_article(article: ArticleInput):
    """
    –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –≤ KB –ø–æ—Å–ª–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (—Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞)
    """
    try:
        if get_article_indexer is None:
            raise HTTPException(status_code=503, detail="ArticleIndexer –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        indexer = get_article_indexer()
        collector = ArticleCollector()
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        validation = await collector.validate_article_relevance(
            title=article.title,
            content=article.content,
            url=article.url
        )
        
        if not validation.get("is_relevant", False):
            raise HTTPException(
                status_code=400,
                detail=f"–°—Ç–∞—Ç—å—è –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞ (relevance_score: {validation.get('relevance_score', 0):.2f})"
            )
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        metadata = await collector.extract_metadata(article.title, article.content)
        
        if not metadata.get("problem_type"):
            raise HTTPException(
                status_code=400,
                detail="–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –ø—Ä–æ–±–ª–µ–º—ã"
            )
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ç–∞—Ç—å–∏
        article_id = f"{metadata['problem_type']}_{abs(hash(article.title)) % 10000}"
        
        article_data = {
            "article_id": article_id,
            "title": article.title,
            "content": article.content,
            "url": article.url or "",
            "section": article.section or "unknown",
            "date": "",
            "relevance_score": validation.get("relevance_score", 0.0),
            "problem_type": metadata.get("problem_type"),
            "printer_models": metadata.get("printer_models", []),
            "materials": metadata.get("materials", []),
            "symptoms": metadata.get("symptoms", []),
            "solutions": metadata.get("solutions", [])
        }
        
        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è
        result = await indexer.index_article(article_data)
        
        if result["success"]:
            return {
                "success": True,
                "article_id": article_id,
                "message": "–°—Ç–∞—Ç—å—è —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ KB",
                "metadata": metadata,
                "validation": validation
            }
        else:
            raise HTTPException(
                status_code=500,
                detail=result.get("error", "–û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/kb/statistics", response_class=UnicodeJSONResponse)
async def get_kb_statistics():
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ KB
    
    Returns:
        {
            "text_articles": –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π,
            "images": –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π,
            "total_vectors": –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ–∫—Ç–æ—Ä–æ–≤
        }
    """
    try:
        from services.vector_db import get_vector_db
        
        db = get_vector_db()
        stats = db.get_statistics()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        try:
            image_collection_info = db.client.get_collection(db.image_collection_name)
            image_count = image_collection_info.points_count
        except Exception:
            image_count = 0
        
        text_count = stats.get("articles_count", 0)
        text_vectors = stats.get("vectors_count", 0)
        
        return {
            "text_articles": text_count,
            "images": image_count,
            "total_vectors": text_vectors + image_count
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/kb/articles/{article_id}", response_class=UnicodeJSONResponse)
async def get_article_by_id(article_id: str):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –ø–æ ID
    
    Args:
        article_id: ID —Å—Ç–∞—Ç—å–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å article_id –∏–ª–∏ original_id)
    
    Returns:
        –ü–æ–ª–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç–∞—Ç—å–µ –∏–ª–∏ –æ—à–∏–±–∫–∞, –µ—Å–ª–∏ —Å—Ç–∞—Ç—å—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
    """
    try:
        from services.vector_db import get_vector_db
        from qdrant_client.models import Filter, FieldCondition, MatchValue
        
        db = get_vector_db()
        
        # –ü–æ–∏—Å–∫ —Å—Ç–∞—Ç—å–∏ –ø–æ ID —á–µ—Ä–µ–∑ scroll
        filter_conditions = [
            FieldCondition(
                key="article_id",
                match=MatchValue(value=article_id)
            )
        ]
        
        qdrant_filter = Filter(must=filter_conditions)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º scroll –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ —Ñ–∏–ª—å—Ç—Ä—É
        result = db.client.scroll(
            collection_name=db.collection_name,
            scroll_filter=qdrant_filter,
            limit=1,
            with_payload=True,
            with_vectors=False
        )
        
        if result[0] and len(result[0]) > 0:
            point = result[0][0]
            article = point.payload
            
            return {
                "article_id": article.get("article_id") or article.get("original_id", "unknown"),
                "title": article.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"),
                "content": article.get("content", ""),
                "url": article.get("url"),
                "problem_type": article.get("problem_type"),
                "printer_models": article.get("printer_models", []),
                "materials": article.get("materials", []),
                "symptoms": article.get("symptoms", []),
                "solutions": article.get("solutions", []),
                "section": article.get("section"),
                "date": article.get("date"),
                "relevance_score": article.get("relevance_score")
            }
        else:
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ original_id
            filter_conditions_orig = [
                FieldCondition(
                    key="original_id",
                    match=MatchValue(value=article_id)
                )
            ]
            
            qdrant_filter_orig = Filter(must=filter_conditions_orig)
            result_orig = db.client.scroll(
                collection_name=db.collection_name,
                scroll_filter=qdrant_filter_orig,
                limit=1,
                with_payload=True,
                with_vectors=False
            )
            
            if result_orig[0] and len(result_orig[0]) > 0:
                point = result_orig[0][0]
                article = point.payload
                
                return {
                    "article_id": article.get("article_id") or article.get("original_id", "unknown"),
                    "title": article.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"),
                    "content": article.get("content", ""),
                    "url": article.get("url"),
                    "problem_type": article.get("problem_type"),
                    "printer_models": article.get("printer_models", []),
                    "materials": article.get("materials", []),
                    "symptoms": article.get("symptoms", []),
                    "solutions": article.get("solutions", []),
                    "section": article.get("section"),
                    "date": article.get("date"),
                    "relevance_score": article.get("relevance_score")
                }
            
            raise HTTPException(status_code=404, detail=f"–°—Ç–∞—Ç—å—è —Å ID '{article_id}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ KB")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/kb/articles", response_class=UnicodeJSONResponse)
async def list_articles(limit: int = 10, offset: int = 0):
    """
    –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –≤ KB
    
    Args:
        limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10)
        offset: –°–º–µ—â–µ–Ω–∏–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0)
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π —Å –∫—Ä–∞—Ç–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
    """
    try:
        from services.vector_db import get_vector_db
        
        db = get_vector_db()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç—å–∏ —á–µ—Ä–µ–∑ scroll
        result = db.client.scroll(
            collection_name=db.collection_name,
            limit=limit + offset,
            with_payload=True,
            with_vectors=False
        )
        
        points = result[0]
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º offset
        articles = []
        for point in points[offset:offset+limit]:
            payload = point.payload
            articles.append({
                "article_id": payload.get("article_id") or payload.get("original_id", f"point_{point.id}"),
                "title": payload.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"),
                "url": payload.get("url"),
                "section": payload.get("section"),
                "problem_type": payload.get("problem_type"),
                "content_preview": payload.get("content", "")[:200] + "..." if len(payload.get("content", "")) > 200 else payload.get("content", "")
            })
        
        return {
            "articles": articles,
            "total": len(points),
            "limit": limit,
            "offset": offset
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Å—Ç–∞—Ç–µ–π: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ========== ENDPOINTS –î–õ–Ø –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô ==========

@app.post("/api/diagnose", response_model=DiagnosticResponse)
async def diagnose_problem(request: DiagnosticRequest):
    """
    –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º—ã 3D-–ø–µ—á–∞—Ç–∏
    """
    try:
        if get_rag_service is None or get_llm_client is None:
            raise HTTPException(status_code=503, detail="–°–µ—Ä–≤–∏—Å—ã –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        
        rag_service = get_rag_service()
        llm_client = get_llm_client()
        
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        filters = {}
        if request.problem_type:
            filters["problem_type"] = request.problem_type
        if request.printer_model:
            filters["printer_models"] = [request.printer_model]
        if request.material:
            filters["materials"] = [request.material]
        
        # –ü–æ–∏—Å–∫ –≤ KB
        search_results = await rag_service.hybrid_search(
            query=request.query,
            filters=filters if filters else None,
            limit=3,
            boost_filters=True
        )
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —É—Ç–æ—á–Ω–µ–Ω–∏–π
        needs_clarification = False
        clarification_questions = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        if not request.printer_model:
            needs_clarification = True
            clarification_questions.append(
                ClarificationQuestion(
                    question="–ö–∞–∫–∞—è —É –≤–∞—Å –º–æ–¥–µ–ª—å –ø—Ä–∏–Ω—Ç–µ—Ä–∞?",
                    question_type="printer_model",
                    options=None  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
                )
            )
        
        if not request.material:
            needs_clarification = True
            clarification_questions.append(
                ClarificationQuestion(
                    question="–ö–∞–∫–æ–π –º–∞—Ç–µ—Ä–∏–∞–ª –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ? (PLA, PETG, ABS, etc.)",
                    question_type="material",
                    options=["PLA", "PETG", "ABS", "TPU", "–î—Ä—É–≥–æ–µ"]
                )
            )
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞, –Ω–æ –∏—Ö –º–∞–ª–æ –∏–ª–∏ –Ω–∏–∑–∫–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
        if search_results and len(search_results) < 2:
            if search_results[0].get("score", 0) < 0.7:
                needs_clarification = True
                clarification_questions.append(
                    ClarificationQuestion(
                        question="–ú–æ–∂–µ—Ç–µ –æ–ø–∏—Å–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—É –ø–æ–¥—Ä–æ–±–Ω–µ–µ? –ß—Ç–æ –∏–º–µ–Ω–Ω–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç?",
                        question_type="symptom",
                        options=None
                    )
                )
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM
        context = ""
        if search_results:
            context = "\n\n".join([
                f"–°—Ç–∞—Ç—å—è: {r.get('title', '')}\n{r.get('content', '')[:500]}..."
                for r in search_results[:3]
            ])
        
        prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –ø—Ä–æ–±–ª–µ–º 3D-–ø–µ—á–∞—Ç–∏.

–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {request.query}
"""
        
        if request.printer_model:
            prompt += f"\n–ú–û–î–ï–õ–¨ –ü–†–ò–ù–¢–ï–†–ê: {request.printer_model}"
        
        if request.material:
            prompt += f"\n–ú–ê–¢–ï–†–ò–ê–õ: {request.material}"
        
        if context:
            prompt += f"\n\n–†–ï–õ–ï–í–ê–ù–¢–ù–´–ï –°–¢–ê–¢–¨–ò –ò–ó –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô:\n{context}"
        
        prompt += """

–ó–ê–î–ê–ß–ê:
1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
2. –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
3. –î–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞, —Å–∫–æ—Ä–æ—Å—Ç—å, retraction)
4. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ - —É–∫–∞–∂–∏, —á—Ç–æ –Ω—É–∂–Ω—ã —É—Ç–æ—á–Ω–µ–Ω–∏—è

–û–¢–í–ï–¢ –î–û–õ–ñ–ï–ù –ë–´–¢–¨:
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º (—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏)
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º (–ø—Ä–æ–±–ª–µ–º–∞ ‚Üí —Ä–µ—à–µ–Ω–∏–µ ‚Üí –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
- –ü–æ–Ω—è—Ç–Ω—ã–º –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- –°—Å—ã–ª–∫–∞–º–∏ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
"""
        
        answer = await llm_client.generate(
            prompt=prompt,
            system_prompt="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –ø—Ä–æ–±–ª–µ–º 3D-–ø–µ—á–∞—Ç–∏. –û—Ç–≤–µ—á–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ."
        )
        
        # –û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        confidence = 0.8 if search_results and search_results[0].get("score", 0) > 0.7 else 0.5
        
        return DiagnosticResponse(
            answer=answer,
            needs_clarification=needs_clarification,
            clarification_questions=clarification_questions if needs_clarification else None,
            relevant_articles=[
                {
                    "title": r.get("title", ""),
                    "url": r.get("url", ""),
                    "score": r.get("score", 0.0)
                }
                for r in search_results[:3]
            ] if search_results else None,
            confidence=confidence
        )
        
    except HTTPException:
        raise
    except ConnectionError as e:
        error_msg = str(e)
        if "ollama" in error_msg.lower() or "connection refused" in error_msg.lower():
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LLM —Å–µ—Ä–≤–∏—Å—É: {e}", exc_info=True)
            raise HTTPException(
                status_code=503,
                detail=(
                    "LLM —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. "
                    "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω (ollama serve) –∏–ª–∏ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –¥—Ä—É–≥–æ–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä (Gemini/OpenAI) –≤ config.env"
                )
            )
        else:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}", exc_info=True)
            raise HTTPException(status_code=503, detail=f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ —Å–µ—Ä–≤–∏—Å—É: {error_msg}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: {e}", exc_info=True)
        error_msg = str(e)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å–≤—è–∑–∞–Ω–∞ –ª–∏ –æ—à–∏–±–∫–∞ —Å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å—é LLM
        if "connection refused" in error_msg.lower() or "errno 111" in error_msg.lower():
            raise HTTPException(
                status_code=503,
                detail=(
                    "LLM —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. "
                    "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ LLM_PROVIDER –≤ config.env –∏ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä –∑–∞–ø—É—â–µ–Ω –∏ –¥–æ—Å—Ç—É–ø–µ–Ω."
                )
            )
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: {error_msg}")


@app.post("/api/diagnose/image")
async def diagnose_with_image(
    query: str,
    printer_model: Optional[str] = None,
    material: Optional[str] = None,
    image: UploadFile = File(...)
):
    """
    –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å –∞–Ω–∞–ª–∏–∑–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç–∞
    """
    try:
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Vision Agent
        # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É
        
        return {
            "message": "–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤ –®–ê–ì–ï 8",
            "query": query,
            "printer_model": printer_model,
            "material": material
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ========== –°–õ–£–ñ–ï–ë–ù–´–ï ENDPOINTS ==========

@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è API"""
    return {
        "status": "healthy",
        "version": "0.1.0"
    }


@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π endpoint"""
    return {
        "message": "3dtoday Diagnostic API",
        "version": "0.1.0",
        "endpoints": {
            "diagnose": "/api/diagnose",
            "kb_validate": "/api/kb/articles/validate",
            "kb_add": "/api/kb/articles/add",
            "kb_statistics": "/api/kb/statistics",
            "health": "/health"
        }
    }


if __name__ == "__main__":
    import uvicorn
    
    host = os.getenv("API_HOST", "0.0.0.0")
    port = int(os.getenv("API_PORT", "8000"))
    
    uvicorn.run(app, host=host, port=port, reload=True)

