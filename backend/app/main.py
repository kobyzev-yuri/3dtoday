"""
FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ 3dtoday
"""

import os
import logging
import base64
import httpx as httpx_client
import tempfile
from pathlib import Path
from typing import Optional, List, Dict, Any
from fastapi import FastAPI, HTTPException, UploadFile, File, Body
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.encoders import jsonable_encoder
import json
from dotenv import load_dotenv

# –ò–º–ø–æ—Ä—Ç –º–æ–¥–µ–ª–µ–π (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å)
try:
    from app.models.schemas import (
        ArticleInput,
        ArticleUpdate,
        DiagnosticRequest,
        DiagnosticResponse,
        ValidationResponse,
        ClarificationQuestion
    )
except ImportError:
    # Fallback –¥–ª—è –ø—Ä—è–º–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).resolve().parent))
    from models.schemas import (
        ArticleInput,
        ArticleUpdate,
        DiagnosticRequest,
        DiagnosticResponse,
        ValidationResponse,
        ClarificationQuestion
    )

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
load_dotenv(dotenv_path=Path(__file__).resolve().parents[2] / "config.env")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å –∑–∞–ø–∏—Å—å—é –≤ —Ñ–∞–π–ª
try:
    from app.utils.logger_config import get_api_logger
    logger = get_api_logger()
except ImportError:
    # Fallback –µ—Å–ª–∏ logger_config –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s"
    )
    logger = logging.getLogger(__name__)

# –ö–∞—Å—Ç–æ–º–Ω—ã–π JSON encoder –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ Unicode
class UnicodeJSONResponse(JSONResponse):
    def render(self, content: Any) -> bytes:
        return json.dumps(
            content,
            ensure_ascii=False,
            allow_nan=False,
            indent=None,
            separators=(",", ":"),
        ).encode("utf-8")


# –°–æ–∑–¥–∞–Ω–∏–µ FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
app = FastAPI(
    title="3dtoday Diagnostic API",
    description="API –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø—Ä–æ–±–ª–µ–º 3D-–ø–µ—á–∞—Ç–∏ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π",
    version="0.1.0"
)

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º UnicodeJSONResponse –∫–∞–∫ –∫–ª–∞—Å—Å –æ—Ç–≤–µ—Ç–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
app.router.default_response_class = UnicodeJSONResponse

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í production –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# –ú–æ–¥–µ–ª–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –∏–∑ models.schemas


# ========== –ò–ú–ü–û–†–¢–´ –°–ï–†–í–ò–°–û–í ==========

try:
    import sys
    from pathlib import Path
    # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
    sys.path.insert(0, str(Path(__file__).resolve().parent))
    
    from services.article_indexer import get_article_indexer
    from services.rag_service import get_rag_service
    from services.llm_client import get_llm_client
    from tools.article_collector import ArticleCollector
except ImportError as e:
    logger.error(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ —Å–µ—Ä–≤–∏—Å–æ–≤: {e}")
    # Fallback –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    get_article_indexer = None
    get_rag_service = None
    get_llm_client = None
    ArticleCollector = None


# ========== ENDPOINTS –î–õ–Ø –ê–î–ú–ò–ù–ò–°–¢–†–ê–¢–û–†–û–í ==========

@app.post("/api/kb/articles/parse_with_llm", response_class=UnicodeJSONResponse)
async def parse_url_with_llm(
    request: Optional[Dict[str, Any]] = Body(None),
    url: Optional[str] = Body(None),
    llm_provider: Optional[str] = Body(None),
    model: Optional[str] = Body(None),
    llm_timeout: Optional[int] = Body(None)
):
    """
    –ü–∞—Ä—Å–∏–Ω–≥ URL –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ LLM (GPT-4o –∏–ª–∏ Gemini 3)
    LLM —Å–∞–º –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç JSON –¥–ª—è KB
    
    Body: {
        "url": "URL –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞",
        "llm_provider": "openai|gemini" (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ),
        "model": "–Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏" (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    }
    
    –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
    - LLM —Å–∞–º –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    - –ë–æ–ª–µ–µ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    - –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ JSON –¥–ª—è KB
    """
    try:
        if request:
            url = url or request.get("url")
            llm_provider = llm_provider or request.get("llm_provider", "openai")
            model = model or request.get("model")
            llm_timeout = llm_timeout or request.get("llm_timeout")
        else:
            url = url
            llm_provider = llm_provider or "openai"
        
        if not url:
            raise HTTPException(status_code=400, detail="url –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω")
        
        if llm_provider not in ["openai", "gemini"]:
            raise HTTPException(status_code=400, detail="llm_provider –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 'openai' –∏–ª–∏ 'gemini'")
        
        from services.llm_url_analyzer import LLMURLAnalyzer
        
        analyzer = LLMURLAnalyzer(llm_provider=llm_provider, model=model, timeout=llm_timeout)
        result = await analyzer.analyze_url(url)
        
        if not result:
            raise HTTPException(status_code=500, detail="–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å URL —á–µ—Ä–µ–∑ LLM")
        
        return {
            "success": True,
            "method": "llm_direct",
            "llm_provider": llm_provider,
            "model": analyzer.model,
            "parsed_document": result
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ URL —á–µ—Ä–µ–∑ LLM: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/kb/articles/parse")
async def parse_document(
    request: Optional[Dict[str, Any]] = Body(None),
    source: Optional[str] = Body(None),
    source_type: Optional[str] = Body(None),
    llm_provider: Optional[str] = Body(None),
    model: Optional[str] = Body(None),
    timeout: Optional[int] = Body(None),
    llm_timeout: Optional[int] = Body(None),
    max_pages: Optional[int] = Body(None)
):
    """
    –ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –∞–≥–µ–Ω—Ç–∞-–±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—è
    
    Body: {
        "source": "URL –∏–ª–∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É, –∏–ª–∏ JSON —Å—Ç—Ä–æ–∫–∞",
        "source_type": "auto|html|pdf|json|url" (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ),
        "llm_provider": "openai|ollama|gemini" (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ),
        "model": "–Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏" (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ),
        "timeout": 180 (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, —Å–µ–∫—É–Ω–¥—ã),
        "max_pages": 30 (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è PDF, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 30 –¥–ª—è Gemini)
    }
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - HTML/URL: —Å—Ç–∞—Ç—å–∏ —Å —Å–∞–π—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 3dtoday.ru)
    - PDF: –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è, –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
    - JSON: –∏–º–ø–æ—Ä—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –±–ª–æ–∫–æ–≤ KB –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    
    –¢–∏–ø—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞:
    - article: —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º 3D-–ø–µ—á–∞—Ç–∏
    - documentation: –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
    - comparison: —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤/–ø—Ä–∏–Ω—Ç–µ—Ä–æ–≤
    - technical: —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
    """
    try:
        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ (request –∫–∞–∫ dict) –∏ –Ω–æ–≤–æ–≥–æ (–æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
        if request:
            source = source or request.get("source") or request.get("url")
            source_type = source_type or request.get("source_type")
            llm_provider = llm_provider or request.get("llm_provider")
            model = model or request.get("model")
            timeout = timeout or request.get("timeout")
            llm_timeout = llm_timeout or request.get("llm_timeout")
            max_pages = max_pages or request.get("max_pages")
        
        if not source:
            raise HTTPException(status_code=400, detail="source –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º source_type –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω
        if not source_type:
            if source.lower().endswith('.pdf'):
                source_type = "pdf"
            elif source.startswith('http://') or source.startswith('https://'):
                source_type = "url"
            else:
                source_type = "json"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        # –î–ª—è PDF –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º Gemini (–ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏)
        if not llm_provider and source_type == "pdf":
            llm_provider = "gemini"
            logger.info(f"üìÑ –î–ª—è PDF –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Gemini –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–ª—É—á—à–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)")
        
        # –î–ª—è Gemini –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º PDF –¥–æ 30 —Å—Ç—Ä–∞–Ω–∏—Ü
        if max_pages is None and llm_provider == "gemini" and source_type == "pdf":
            max_pages = 30
            logger.info(f"üìÑ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ PDF –¥–æ {max_pages} —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è Gemini")
        
        # –í—Ä–µ–º–µ–Ω–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –∏ –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã
        original_provider = None
        original_model = None
        
        if llm_provider:
            original_provider = os.getenv("LLM_PROVIDER")
            os.environ["LLM_PROVIDER"] = llm_provider
        
        if model:
            if llm_provider == "openai":
                original_model = os.getenv("OPENAI_MODEL")
                os.environ["OPENAI_MODEL"] = model
            elif llm_provider == "ollama":
                original_model = os.getenv("OLLAMA_MODEL")
                os.environ["OLLAMA_MODEL"] = model
            elif llm_provider == "gemini":
                original_model = os.getenv("GEMINI_MODEL")
                os.environ["GEMINI_MODEL"] = model
        
        if timeout:
            os.environ["MCP_SERVER_TIMEOUT"] = str(timeout)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        from services.document_parser import DocumentParser
        from agents.kb_librarian import KBLibrarianAgent
        
        logger.info(f"üì• –ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: source_type={source_type}, llm_provider={llm_provider}, max_pages={max_pages}")
        
        parser = DocumentParser()
        doc_data = await parser.parse_document(source, source_type, max_pages=max_pages)
        
        if not doc_data:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç: {source[:100]}")
            raise HTTPException(status_code=404, detail="–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç")
        
        logger.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω: title={doc_data.get('title', 'N/A')[:50]}, content_length={len(doc_data.get('content', ''))}, images_count={len(doc_data.get('images', []))}")
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–π KB
        images = doc_data.get("images", [])
        if images:
            logger.info(f"üì∑ –ù–∞–π–¥–µ–Ω–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ")
            # –ê–≥–µ–Ω—Ç-–±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å –ø—Ä–æ–≤–µ—Ä–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ
            # –ü–æ–∫–∞ –ø–µ—Ä–µ–¥–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –≤ review_and_decide
        
        # –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª: –∞–Ω–∞–ª–∏–∑ + —Ä–µ—à–µ–Ω–∏–µ –æ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ –∞–≥–µ–Ω—Ç–∞-–±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—è
        # –ü–µ—Ä–µ–¥–∞–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä –∏ –º–æ–¥–µ–ª—å –≤ –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º llm_timeout –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω, –∏–Ω–∞—á–µ timeout (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        final_llm_timeout = llm_timeout or timeout
        logger.info(f"ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞-–±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—è: llm_provider={llm_provider}, model={model}, timeout={final_llm_timeout}")
        
        try:
            librarian = KBLibrarianAgent(llm_provider=llm_provider, model=model, timeout=final_llm_timeout)
            logger.info(f"üìã –ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞ —á–µ—Ä–µ–∑ –∞–≥–µ–Ω—Ç–∞-–±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—è...")
            review_result = await librarian.review_and_decide(
                title=doc_data["title"],
                content=doc_data["content"],
                images=images,  # –ü–µ—Ä–µ–¥–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                url=doc_data.get("url"),
                content_type=doc_data.get("content_type"),
                is_questions_list=doc_data.get("is_questions_list", False)
            )
            logger.info(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: relevance_score={review_result.get('relevance_score', 'N/A')}")
            
            # –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, –ø–æ–º–µ—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–∞–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ
            if review_result.get("is_relevant", False) and images:
                logger.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±—É–¥—É—Ç –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω—ã –≤ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—É—é KB")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —á–µ—Ä–µ–∑ –∞–≥–µ–Ω—Ç–∞-–±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—è: {e}", exc_info=True)
            raise
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        if original_provider:
            os.environ["LLM_PROVIDER"] = original_provider
        if original_model:
            if llm_provider == "openai":
                os.environ["OPENAI_MODEL"] = original_model
            elif llm_provider == "ollama":
                os.environ["OLLAMA_MODEL"] = original_model
            elif llm_provider == "gemini":
                os.environ["GEMINI_MODEL"] = original_model
        
        return {
            "success": True,
            "parsed_document": doc_data,
            "review": review_result
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/kb/articles/validate", response_model=ValidationResponse)
async def validate_article(article: ArticleInput):
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Å—Ç–∞—Ç—å–∏ –ø–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –≤ KB
    """
    try:
        if ArticleCollector is None:
            raise HTTPException(status_code=503, detail="ArticleCollector –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        collector = ArticleCollector()
        
        validation = await collector.validate_article_relevance(
            title=article.title,
            content=article.content,
            url=article.url
        )
        
        metadata = None
        if validation.get("is_relevant", False):
            metadata = await collector.extract_metadata(article.title, article.content)
        
        return ValidationResponse(
            is_relevant=validation.get("is_relevant", False),
            relevance_score=validation.get("relevance_score", 0.0),
            quality_score=validation.get("quality_score", 0.0),
            has_solutions=validation.get("has_solutions", False),
            issues=validation.get("issues", []),
            recommendations=validation.get("recommendations", []),
            metadata=metadata
        )
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å—Ç–∞—Ç—å–∏: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/kb/articles/add_from_parse", response_class=UnicodeJSONResponse)
async def add_article_from_parse(request: Dict[str, Any] = Body(...)):
    """
    –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –≤ KB –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å —É—á–µ—Ç–æ–º —Ä–µ—à–µ–Ω–∏—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
    """
    try:
        if get_article_indexer is None:
            raise HTTPException(status_code=503, detail="ArticleIndexer –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        parsed_document = request.get("parsed_document", {})
        review = request.get("review", {})
        admin_decision = request.get("admin_decision", "needs_review")
        relevance_threshold = request.get("relevance_threshold", 0.6)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ—à–µ–Ω–∏—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
        if admin_decision != "approve":
            raise HTTPException(
                status_code=400,
                detail=f"–°—Ç–∞—Ç—å—è –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∞: —Ä–µ—à–µ–Ω–∏–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ - {admin_decision}"
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø–æ—Ä–æ–≥–∞
        relevance_score = review.get("relevance_score", 0.0)
        if relevance_score < relevance_threshold:
            raise HTTPException(
                status_code=400,
                detail=(
                    f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å ({relevance_score:.2f}) –Ω–∏–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞ "
                    f"({relevance_threshold:.2f}). –°—Ç–∞—Ç—å—è –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏."
                )
            )
        
        indexer = get_article_indexer()
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç—å–∏ –∏–∑ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        title = parsed_document.get("title", "")
        content = parsed_document.get("content", "")
        url = parsed_document.get("url", "")
        section = parsed_document.get("section", "unknown")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è article_id
        article_id = f"{section}_{abs(hash(title)) % 10000}"
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ review
        summary = review.get("summary", {})
        content_type = summary.get("content_type", "article") if summary else parsed_document.get("content_type", "article")
        
        article_data = {
            "article_id": article_id,
            "title": title,
            "content": content,
            "url": url,
            "section": section,
            "date": parsed_document.get("date", ""),
            "relevance_score": relevance_score,
            "quality_score": review.get("quality_score", 0.0),
            "content_type": content_type,
            "problem": summary.get("problem", "") if summary else "",
            "symptoms": summary.get("symptoms", []) if summary else [],
            "solutions": summary.get("solutions", []) if summary else [],
            "printer_models": summary.get("printer_models", []) if summary else [],
            "materials": summary.get("materials", []) if summary else [],
            "abstract": review.get("abstract", ""),
            "admin_decision": admin_decision,
            "librarian_decision": review.get("decision", "needs_review"),
            "relevance_threshold_used": relevance_threshold
        }
        
        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏
        result = await indexer.index_article(article_data)
        
        if result["success"]:
            # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –µ—Å–ª–∏ –µ—Å—Ç—å
            images = parsed_document.get("images", [])
            if images:
                # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∏—Ä—É—é—Ç—Å—è –≤ –¥—Ä—É–≥–æ–º –º–µ—Å—Ç–µ (–≤ –±–æ–ª–µ–µ –ø–æ–ª–Ω–æ–π –≤–µ—Ä—Å–∏–∏ endpoint)
                # –ó–¥–µ—Å—å –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º, —á—Ç–æ –æ–Ω–∏ –µ—Å—Ç—å
                logger.info(f"üì∑ –ù–∞–π–¥–µ–Ω–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Å—Ç–∞—Ç—å–µ. –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏ endpoint.")
            
            return {
                "success": True,
                "article_id": article_id,
                "message": "–°—Ç–∞—Ç—å—è —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ KB",
                "relevance_score": relevance_score,
                "relevance_threshold": relevance_threshold,
                "admin_decision": admin_decision
            }
        else:
            raise HTTPException(status_code=500, detail=result.get("error", "–û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"))
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏ –∏–∑ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/kb/articles/add_from_parse", response_class=UnicodeJSONResponse)
async def add_article_from_parse(request: Dict[str, Any] = Body(...)):
    """
    –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –≤ KB –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å —É—á–µ—Ç–æ–º —Ä–µ—à–µ–Ω–∏—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
    """
    try:
        if get_article_indexer is None:
            raise HTTPException(status_code=503, detail="ArticleIndexer –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        parsed_document = request.get("parsed_document", {})
        review = request.get("review", {})
        admin_decision = request.get("admin_decision", "needs_review")
        relevance_threshold = request.get("relevance_threshold", 0.6)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ—à–µ–Ω–∏—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
        if admin_decision != "approve":
            raise HTTPException(
                status_code=400,
                detail=f"–°—Ç–∞—Ç—å—è –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∞: —Ä–µ—à–µ–Ω–∏–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ - {admin_decision}"
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø–æ—Ä–æ–≥–∞
        relevance_score = review.get("relevance_score", 0.0)
        if relevance_score < relevance_threshold:
            raise HTTPException(
                status_code=400,
                detail=(
                    f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å ({relevance_score:.2f}) –Ω–∏–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞ "
                    f"({relevance_threshold:.2f}). –°—Ç–∞—Ç—å—è –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏."
                )
            )
        
        indexer = get_article_indexer()
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç—å–∏ –∏–∑ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        title = parsed_document.get("title", "")
        content = parsed_document.get("content", "")
        url = parsed_document.get("url", "")
        section = parsed_document.get("section", "unknown")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è article_id
        article_id = f"{section}_{abs(hash(title)) % 10000}"
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ review
        summary = review.get("summary", {})
        content_type = summary.get("content_type", "article") if summary else parsed_document.get("content_type", "article")
        
        article_data = {
            "article_id": article_id,
            "title": title,
            "content": content,
            "url": url,
            "section": section,
            "date": parsed_document.get("date", ""),
            "relevance_score": relevance_score,
            "quality_score": review.get("quality_score", 0.0),
            "content_type": content_type,
            "problem": summary.get("problem", "") if summary else "",
            "symptoms": summary.get("symptoms", []) if summary else [],
            "solutions": summary.get("solutions", []) if summary else [],
            "printer_models": summary.get("printer_models", []) if summary else [],
            "materials": summary.get("materials", []) if summary else [],
            "abstract": review.get("abstract", ""),
            "admin_decision": admin_decision,
            "librarian_decision": review.get("decision", "needs_review"),
            "relevance_threshold_used": relevance_threshold
        }
        
        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏
        result = await indexer.index_article(article_data)
        
        if result["success"]:
            # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –µ—Å–ª–∏ –µ—Å—Ç—å
            images = parsed_document.get("images", [])
            indexed_images = []
            if images:
                from app.services.vision_analyzer import VisionAnalyzer
                from app.agents.kb_librarian import KBLibrarianAgent
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º VisionAnalyzer –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                vision_analyzer = VisionAnalyzer(prefer_ollama=False)
                availability = vision_analyzer.check_availability()
                
                if availability.get('available', False):
                    logger.info(f"üì∑ –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ {availability.get('provider', 'unknown')}")
                    
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ 20 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (—É–≤–µ–ª–∏—á–∏–ª–∏ –ª–∏–º–∏—Ç)
                    for img_idx, img_data in enumerate(images[:20]):
                        try:
                            if isinstance(img_data, dict):
                                img_url = img_data.get("url", "")
                                img_title = img_data.get("title", img_data.get("alt", f"Image {img_idx + 1}"))
                                img_base64 = img_data.get("data")  # Base64 –¥–∞–Ω–Ω—ã–µ, –µ—Å–ª–∏ –µ—Å—Ç—å
                            else:
                                img_url = str(img_data)
                                img_title = f"Image {img_idx + 1}"
                                img_base64 = None
                            
                            if not img_url and not img_base64:
                                continue
                            
                            # –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Vision API
                            try:
                                if img_base64:
                                    # –ï—Å–ª–∏ –µ—Å—Ç—å base64 –¥–∞–Ω–Ω—ã–µ (–∏–∑ PDF)
                                    analysis_result = vision_analyzer.analyze_image_from_base64(img_base64, img_title)
                                elif img_url.startswith('http'):
                                    # –ï—Å–ª–∏ —ç—Ç–æ URL - —Å–∫–∞—á–∏–≤–∞–µ–º –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
                                    analysis_result = vision_analyzer.analyze_image_from_url(img_url, img_title)
                                else:
                                    # –õ–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
                                    analysis_result = vision_analyzer.analyze_image_from_path(Path(img_url))
                                
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞ –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                                if analysis_result and analysis_result.get("success", False):
                                    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –∞–Ω–∞–ª–∏–∑–∞
                                    analysis_text = analysis_result.get("analysis", "")
                                    
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫ 3D-–ø–µ—á–∞—Ç–∏
                                    relevance_check = vision_analyzer.check_relevance_to_3d_printing(analysis_text, img_title)
                                    
                                    if not relevance_check.get("success", False) or not relevance_check.get("is_relevant", True):
                                        logger.info(f"‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {img_idx + 1} –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ 3D-–ø–µ—á–∞—Ç–∏, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                                        continue
                                    
                                    # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
                                    image_metadata = {
                                        "article_id": f"{article_id}_img_{img_idx + 1}",
                                        "title": img_title,
                                        "content": analysis_text,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞–∫ content
                                        "abstract": analysis_text[:500] if len(analysis_text) > 500 else analysis_text,  # –ö—Ä–∞—Ç–∫–∏–π –∞–±—Å—Ç—Ä–∞–∫—Ç
                                        "problem_type": relevance_check.get("problem_type") or (summary.get("problem_type") if summary else None),
                                        "printer_models": relevance_check.get("printer_models", []) or (summary.get("printer_models", []) if summary else []),
                                        "materials": relevance_check.get("materials", []) or (summary.get("materials", []) if summary else []),
                                        "symptoms": summary.get("symptoms", []) if summary else []
                                    }
                                    
                                    # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
                                    import tempfile
                                    import httpx as httpx_client
                                    
                                    temp_dir = Path(tempfile.gettempdir()) / "kb_images"
                                    temp_dir.mkdir(exist_ok=True)
                                    
                                    if img_base64:
                                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º base64 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                                        image_bytes = base64.b64decode(img_base64)
                                        temp_path = temp_dir / f"{article_id}_img_{img_idx + 1}.jpg"
                                        with open(temp_path, 'wb') as f:
                                            f.write(image_bytes)
                                    elif img_url.startswith('http'):
                                        # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ URL
                                        async with httpx_client.AsyncClient(timeout=30) as client:
                                            img_response = await client.get(img_url)
                                            img_response.raise_for_status()
                                            temp_path = temp_dir / f"{article_id}_img_{img_idx + 1}.jpg"
                                            with open(temp_path, 'wb') as f:
                                                f.write(img_response.content)
                                    else:
                                        temp_path = Path(img_url)
                                    
                                    # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                                    index_result = await indexer.index_image(
                                        image_data=image_metadata,
                                        image_path=str(temp_path),
                                        generate_embedding=True
                                    )
                                    
                                    if index_result.get("success"):
                                        indexed_images.append({
                                            "image_id": image_metadata["article_id"],
                                            "abstract": image_metadata.get("abstract", "")
                                        })
                                        logger.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {img_idx + 1} –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ")
                                    
                            except Exception as img_error:
                                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {img_idx + 1}: {img_error}")
                                
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {img_idx + 1}: {e}")
                else:
                    logger.warning(f"‚ö†Ô∏è Vision API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ({availability.get('message', 'unknown')}), –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –±—É–¥—É—Ç –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
            
            return {
                "success": True,
                "article_id": article_id,
                "message": "–°—Ç–∞—Ç—å—è —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ KB",
                "relevance_score": relevance_score,
                "relevance_threshold": relevance_threshold,
                "admin_decision": admin_decision
            }
        else:
            raise HTTPException(status_code=500, detail=result.get("error", "–û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏"))
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏ –∏–∑ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/kb/articles/add")
async def add_article(article: ArticleInput):
    """
    –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –≤ KB –ø–æ—Å–ª–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (—Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞)
    """
    try:
        if get_article_indexer is None:
            raise HTTPException(status_code=503, detail="ArticleIndexer –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        indexer = get_article_indexer()
        collector = ArticleCollector()
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        validation = await collector.validate_article_relevance(
            title=article.title,
            content=article.content,
            url=article.url
        )
        
        if not validation.get("is_relevant", False):
            raise HTTPException(
                status_code=400,
                detail=f"–°—Ç–∞—Ç—å—è –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞ (relevance_score: {validation.get('relevance_score', 0):.2f})"
            )
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        metadata = await collector.extract_metadata(article.title, article.content)
        
        if not metadata.get("problem_type"):
            raise HTTPException(
                status_code=400,
                detail="–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –ø—Ä–æ–±–ª–µ–º—ã"
            )
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å—Ç–∞—Ç—å–∏
        article_id = f"{metadata['problem_type']}_{abs(hash(article.title)) % 10000}"
        
        article_data = {
            "article_id": article_id,
            "title": article.title,
            "content": article.content,
            "url": article.url or "",
            "section": article.section or "unknown",
            "date": "",
            "relevance_score": validation.get("relevance_score", 0.0),
            "problem_type": metadata.get("problem_type"),
            "printer_models": metadata.get("printer_models", []),
            "materials": metadata.get("materials", []),
            "symptoms": metadata.get("symptoms", []),
            "solutions": metadata.get("solutions", [])
        }
        
        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è
        result = await indexer.index_article(article_data)
        
        if result["success"]:
            return {
                "success": True,
                "article_id": article_id,
                "message": "–°—Ç–∞—Ç—å—è —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ KB",
                "metadata": metadata,
                "validation": validation
            }
        else:
            raise HTTPException(
                status_code=500,
                detail=result.get("error", "–û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/kb/statistics", response_class=UnicodeJSONResponse)
async def get_kb_statistics():
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ KB
    
    Returns:
        {
            "text_articles": –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π,
            "images": –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π,
            "total_vectors": –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ–∫—Ç–æ—Ä–æ–≤
        }
    """
    try:
        from services.vector_db import get_vector_db
        
        db = get_vector_db()
        stats = db.get_statistics()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        try:
            image_collection_info = db.client.get_collection(db.image_collection_name)
            image_count = image_collection_info.points_count
        except Exception:
            image_count = 0
        
        text_count = stats.get("articles_count", 0)
        text_vectors = stats.get("vectors_count", 0)
        
        return {
            "text_articles": text_count,
            "images": image_count,
            "total_vectors": text_vectors + image_count
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/kb/articles/{article_id}", response_class=UnicodeJSONResponse)
async def get_article_by_id(article_id: str):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –ø–æ ID
    
    Args:
        article_id: ID —Å—Ç–∞—Ç—å–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å article_id –∏–ª–∏ original_id)
    
    Returns:
        –ü–æ–ª–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç–∞—Ç—å–µ –∏–ª–∏ –æ—à–∏–±–∫–∞, –µ—Å–ª–∏ —Å—Ç–∞—Ç—å—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
    """
    try:
        from services.vector_db import get_vector_db
        from qdrant_client.models import Filter, FieldCondition, MatchValue
        
        db = get_vector_db()
        
        # –ü–æ–∏—Å–∫ —Å—Ç–∞—Ç—å–∏ –ø–æ ID —á–µ—Ä–µ–∑ scroll
        filter_conditions = [
            FieldCondition(
                key="article_id",
                match=MatchValue(value=article_id)
            )
        ]
        
        qdrant_filter = Filter(must=filter_conditions)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º scroll –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ —Ñ–∏–ª—å—Ç—Ä—É
        result = db.client.scroll(
            collection_name=db.collection_name,
            scroll_filter=qdrant_filter,
            limit=1,
            with_payload=True,
            with_vectors=False
        )
        
        if result[0] and len(result[0]) > 0:
            point = result[0][0]
            article = point.payload
            
            return {
                "article_id": article.get("article_id") or article.get("original_id", "unknown"),
                "title": article.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"),
                "content": article.get("content", ""),
                "url": article.get("url"),
                "problem_type": article.get("problem_type"),
                "printer_models": article.get("printer_models", []),
                "materials": article.get("materials", []),
                "symptoms": article.get("symptoms", []),
                "solutions": article.get("solutions", []),
                "section": article.get("section"),
                "date": article.get("date"),
                "relevance_score": article.get("relevance_score")
            }
        else:
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ original_id
            filter_conditions_orig = [
                FieldCondition(
                    key="original_id",
                    match=MatchValue(value=article_id)
                )
            ]
            
            qdrant_filter_orig = Filter(must=filter_conditions_orig)
            result_orig = db.client.scroll(
                collection_name=db.collection_name,
                scroll_filter=qdrant_filter_orig,
                limit=1,
                with_payload=True,
                with_vectors=False
            )
            
            if result_orig[0] and len(result_orig[0]) > 0:
                point = result_orig[0][0]
                article = point.payload
                
                return {
                    "article_id": article.get("article_id") or article.get("original_id", "unknown"),
                    "title": article.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"),
                    "content": article.get("content", ""),
                    "url": article.get("url"),
                    "problem_type": article.get("problem_type"),
                    "printer_models": article.get("printer_models", []),
                    "materials": article.get("materials", []),
                    "symptoms": article.get("symptoms", []),
                    "solutions": article.get("solutions", []),
                    "section": article.get("section"),
                    "date": article.get("date"),
                    "relevance_score": article.get("relevance_score")
                }
            
            raise HTTPException(status_code=404, detail=f"–°—Ç–∞—Ç—å—è —Å ID '{article_id}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ KB")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/kb/articles", response_class=UnicodeJSONResponse)
async def list_articles(limit: int = 10, offset: int = 0):
    """
    –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –≤ KB
    
    Args:
        limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10)
        offset: –°–º–µ—â–µ–Ω–∏–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0)
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π —Å –∫—Ä–∞—Ç–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
    """
    try:
        from services.vector_db import get_vector_db
        
        db = get_vector_db()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç—å–∏ —á–µ—Ä–µ–∑ scroll
        result = db.client.scroll(
            collection_name=db.collection_name,
            limit=limit + offset,
            with_payload=True,
            with_vectors=False
        )
        
        points = result[0]
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º offset
        articles = []
        for point in points[offset:offset+limit]:
            payload = point.payload
            articles.append({
                "article_id": payload.get("article_id") or payload.get("original_id", f"point_{point.id}"),
                "title": payload.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"),
                "url": payload.get("url"),
                "section": payload.get("section"),
                "problem_type": payload.get("problem_type"),
                "content_preview": payload.get("content", "")[:200] + "..." if len(payload.get("content", "")) > 200 else payload.get("content", "")
            })
        
        return {
            "articles": articles,
            "total": len(points),
            "limit": limit,
            "offset": offset
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Å—Ç–∞—Ç–µ–π: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/kb/articles/{article_id}", response_class=UnicodeJSONResponse)
async def delete_article(article_id: str):
    """
    –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –ø–æ ID
    
    Args:
        article_id: ID —Å—Ç–∞—Ç—å–∏
    
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç —É–¥–∞–ª–µ–Ω–∏—è
    """
    try:
        from services.vector_db import get_vector_db
        
        db = get_vector_db()
        
        success = await db.delete_article(article_id)
        
        if success:
            return {
                "success": True,
                "message": f"–°—Ç–∞—Ç—å—è {article_id} —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–∞",
                "article_id": article_id
            }
        else:
            raise HTTPException(
                status_code=404,
                detail=f"–°—Ç–∞—Ç—å—è —Å ID {article_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
            )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.put("/api/kb/articles/{article_id}", response_class=UnicodeJSONResponse)
async def update_article(article_id: str, article_update: ArticleUpdate):
    """
    –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –ø–æ ID
    
    Args:
        article_id: ID —Å—Ç–∞—Ç—å–∏
        article_update: –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    
    Returns:
        –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è
    """
    try:
        from services.vector_db import get_vector_db
        
        db = get_vector_db()
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è (—Ç–æ–ª—å–∫–æ –Ω–µ-None –ø–æ–ª—è)
        update_data = {}
        if article_update.title is not None:
            update_data["title"] = article_update.title
        if article_update.content is not None:
            update_data["content"] = article_update.content
        if article_update.url is not None:
            update_data["url"] = article_update.url
        if article_update.section is not None:
            update_data["section"] = article_update.section
        if article_update.problem_type is not None:
            update_data["problem_type"] = article_update.problem_type
        if article_update.printer_models is not None:
            update_data["printer_models"] = article_update.printer_models
        if article_update.materials is not None:
            update_data["materials"] = article_update.materials
        if article_update.symptoms is not None:
            update_data["symptoms"] = article_update.symptoms
        if article_update.solutions is not None:
            update_data["solutions"] = article_update.solutions
        
        if not update_data:
            raise HTTPException(
                status_code=400,
                detail="–ù–µ —É–∫–∞–∑–∞–Ω—ã –ø–æ–ª—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"
            )
        
        success = await db.update_article(
            article_id=article_id,
            article_data=update_data,
            regenerate_embedding=article_update.regenerate_embedding
        )
        
        if success:
            # –ü–æ–ª—É—á–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é —Å—Ç–∞—Ç—å—é
            from qdrant_client.models import Filter, FieldCondition, MatchValue
            
            filter_conditions = [
                FieldCondition(
                    key="article_id",
                    match=MatchValue(value=article_id)
                )
            ]
            
            qdrant_filter = Filter(must=filter_conditions)
            
            result = db.client.scroll(
                collection_name=db.collection_name,
                scroll_filter=qdrant_filter,
                limit=1,
                with_payload=True,
                with_vectors=False
            )
            
            if result[0] and len(result[0]) > 0:
                point = result[0][0]
                article = point.payload
                
                return {
                    "success": True,
                    "message": f"–°—Ç–∞—Ç—å—è {article_id} —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞",
                    "article": {
                        "article_id": article.get("article_id") or article.get("original_id", "unknown"),
                        "title": article.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"),
                        "content": article.get("content", ""),
                        "url": article.get("url"),
                        "problem_type": article.get("problem_type"),
                        "printer_models": article.get("printer_models", []),
                        "materials": article.get("materials", []),
                        "symptoms": article.get("symptoms", []),
                        "solutions": article.get("solutions", []),
                        "section": article.get("section"),
                        "date": article.get("date"),
                        "relevance_score": article.get("relevance_score")
                    }
                }
            else:
                raise HTTPException(
                    status_code=404,
                    detail=f"–°—Ç–∞—Ç—å—è —Å ID {article_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"
                )
        else:
            raise HTTPException(
                status_code=404,
                detail=f"–°—Ç–∞—Ç—å—è —Å ID {article_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
            )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/kb/metadata/unique-values", response_class=UnicodeJSONResponse)
async def get_unique_metadata_values():
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –∏ –ø—Ä–∏–Ω—Ç–µ—Ä–æ–≤ –∏–∑ KB
    
    Returns:
        {
            "materials": ["PLA", "PETG", "ABS", ...],
            "printer_models": ["Ender-3", "Anycubic Kobra", ...]
        }
    """
    try:
        from services.vector_db import get_vector_db
        
        db = get_vector_db()
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ç–æ—á–∫–∏ —á–µ—Ä–µ–∑ scroll (—Å –±–æ–ª—å—à–∏–º –ª–∏–º–∏—Ç–æ–º)
        materials_set = set()
        printer_models_set = set()
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º scroll –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö —Ç–æ—á–µ–∫
        limit = 10000  # –ë–æ–ª—å—à–æ–π –ª–∏–º–∏—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π
        offset = 0
        
        while True:
            result = db.client.scroll(
                collection_name=db.collection_name,
                limit=limit,
                offset=offset,
                with_payload=True,
                with_vectors=False
            )
            
            points = result[0]
            if not points:
                break
            
            # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            for point in points:
                payload = point.payload or {}
                
                # –ú–∞—Ç–µ—Ä–∏–∞–ª—ã
                materials = payload.get("materials", [])
                if isinstance(materials, list):
                    for material in materials:
                        if material and isinstance(material, str):
                            materials_set.add(material.strip())
                
                # –ú–æ–¥–µ–ª–∏ –ø—Ä–∏–Ω—Ç–µ—Ä–æ–≤
                printer_models = payload.get("printer_models", [])
                if isinstance(printer_models, list):
                    for printer_model in printer_models:
                        if printer_model and isinstance(printer_model, str):
                            printer_models_set.add(printer_model.strip())
            
            # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –º–µ–Ω—å—à–µ, —á–µ–º –ª–∏–º–∏—Ç, –∑–Ω–∞—á–∏—Ç —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
            if len(points) < limit:
                break
            
            offset += limit
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
        materials_list = sorted(list(materials_set), key=str.lower)
        printer_models_list = sorted(list(printer_models_set), key=str.lower)
        
        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤: {len(materials_list)}, –ø—Ä–∏–Ω—Ç–µ—Ä–æ–≤: {len(printer_models_list)}")
        
        return {
            "materials": materials_list,
            "printer_models": printer_models_list
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/kb/examples/relevant", response_class=UnicodeJSONResponse)
async def get_relevant_examples(
    candidate_queries: Optional[str] = None,
    limit: int = 8,
    min_score: float = 0.3
):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ KB
    
    Args:
        candidate_queries: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏)
        limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 8)
        min_score: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π score —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.3)
    
    Returns:
        {
            "examples": [
                {
                    "query": "–£ –º–µ–Ω—è –ø–æ—è–≤–ª—è—é—Ç—Å—è –Ω–∏—Ç–æ—á–∫–∏...",
                    "score": 0.85,
                    "has_relevant_articles": true
                }
            ]
        }
    """
    try:
        from services.rag_service import get_rag_service
        
        rag_service = get_rag_service()
        relevant_examples = []
        
        # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã –∫–∞–Ω–¥–∏–¥–∞—Ç—ã, –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
        if candidate_queries:
            candidates = [q.strip() for q in candidate_queries.split(",") if q.strip()]
            logger.info(f"Checking {len(candidates)} candidate queries for relevance")
            
            for query in candidates:
                try:
                    # –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –≤ KB –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                    results = await rag_service.hybrid_search(
                        query=query,
                        limit=1,  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–¥–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                        boost_filters=False
                    )
                    
                    if results and len(results) > 0:
                        score = results[0].get("score", 0.0)
                        if score >= min_score:
                            relevant_examples.append({
                                "query": query,
                                "score": round(score, 2),
                                "has_relevant_articles": True
                            })
                            logger.debug(f"Query '{query[:50]}...' is relevant (score: {score:.2f})")
                        else:
                            logger.debug(f"Query '{query[:50]}...' has low relevance (score: {score:.2f})")
                    else:
                        logger.debug(f"Query '{query[:50]}...' has no results in KB")
                except Exception as e:
                    logger.warning(f"Error checking query '{query[:50]}...': {e}")
                    continue
        
        # –ï—Å–ª–∏ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã –∏–ª–∏ –∏—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã –∏–∑ KB
        if len(relevant_examples) < limit:
            logger.info("Generating examples from KB articles")
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç—å–∏ –∏–∑ KB
            from services.vector_db import get_vector_db
            db = get_vector_db()
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
            result = db.client.scroll(
                collection_name=db.collection_name,
                limit=min(limit * 3, 100),  # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ, —á—Ç–æ–±—ã –≤—ã–±—Ä–∞—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ
                with_payload=True,
                with_vectors=False
            )
            
            points = result[0]
            seen_queries = {ex["query"] for ex in relevant_examples}
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
            for point in points:
                if len(relevant_examples) >= limit:
                    break
                
                payload = point.payload or {}
                title = payload.get("title", "")
                problem_type = payload.get("problem_type", "")
                materials = payload.get("materials", [])
                printer_models = payload.get("printer_models", [])
                
                # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç—å–∏
                examples_from_article = []
                
                # –ü—Ä–∏–º–µ—Ä 1: –ù–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ (–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å)
                if title:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    title_lower = title.lower()
                    
                    # –ï—Å–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —É–∂–µ –ø–æ—Ö–æ–∂ –Ω–∞ –≤–æ–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ –µ—Å—Ç—å
                    if any(word in title_lower for word in ["–∫–∞–∫", "–ø–æ—á–µ–º—É", "—á—Ç–æ", "–∏—â—É", "–ø–æ–º–æ–≥–∏—Ç–µ", "–ø—Ä–æ–±–ª–µ–º–∞"]):
                        query = title
                    # –ï—Å–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ–ø–∏—Å—ã–≤–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –∑–∞–ø—Ä–æ—Å
                    elif problem_type:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏
                        problem_names = {
                            "stringing": "–Ω–∏—Ç–æ—á–∫–∏ –º–µ–∂–¥—É –¥–µ—Ç–∞–ª—è–º–∏",
                            "warping": "–æ—Ç—Å–ª–æ–µ–Ω–∏–µ –æ—Ç —Å—Ç–æ–ª–∞",
                            "layer_separation": "—Ç—Ä–µ—â–∏–Ω—ã –≤ —Å–ª–æ—è—Ö",
                            "bed_adhesion": "–ø–ª–æ—Ö–æ–µ –ø—Ä–∏–ª–∏–ø–∞–Ω–∏–µ –∫ —Å—Ç–æ–ª—É",
                            "overhang": "–ø—Ä–æ–±–ª–µ–º—ã —Å –Ω–∞–≤–∏—Å–∞—é—â–∏–º–∏ —á–∞—Å—Ç—è–º–∏",
                            "underextrusion": "–Ω–µ–¥–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ",
                            "overextrusion": "–ø–µ—Ä–µ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ"
                        }
                        problem_name = problem_names.get(problem_type, problem_type)
                        
                        if materials and printer_models:
                            query = f"–£ –º–µ–Ω—è –ø–æ—è–≤–ª—è—é—Ç—Å—è {problem_name} –ø—Ä–∏ –ø–µ—á–∞—Ç–∏ {materials[0]} –Ω–∞ {printer_models[0]}"
                        elif materials:
                            query = f"–£ –º–µ–Ω—è –ø–æ—è–≤–ª—è—é—Ç—Å—è {problem_name} –ø—Ä–∏ –ø–µ—á–∞—Ç–∏ {materials[0]}"
                        else:
                            query = f"–ü—Ä–æ–±–ª–µ–º–∞ —Å {problem_name}"
                    else:
                        # –û–±—â–∏–π –∑–∞–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞
                        query = f"–ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ {title.lower()}"
                    
                    if query not in seen_queries and len(query) > 10:
                        examples_from_article.append(query)
                
                # –ü—Ä–∏–º–µ—Ä 2: –ù–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å)
                if materials and printer_models and problem_type:
                    material = materials[0]
                    printer = printer_models[0]
                    
                    problem_names = {
                        "stringing": "–Ω–∏—Ç–æ—á–∫–∏ –º–µ–∂–¥—É –¥–µ—Ç–∞–ª—è–º–∏",
                        "warping": "–æ—Ç—Å–ª–∞–∏–≤–∞–µ—Ç—Å—è –æ—Ç —Å—Ç–æ–ª–∞",
                        "layer_separation": "—Ç—Ä–µ—â–∏–Ω—ã –≤ —Å–ª–æ—è—Ö",
                        "bed_adhesion": "–Ω–µ –ø—Ä–∏–ª–∏–ø–∞–µ—Ç –∫ —Å—Ç–æ–ª—É",
                        "overhang": "–ø–ª–æ—Ö–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞–≤–∏—Å–∞—é—â–∏—Ö —á–∞—Å—Ç–µ–π",
                        "underextrusion": "–Ω–µ–¥–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ",
                        "overextrusion": "–ø–µ—Ä–µ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ"
                    }
                    problem_name = problem_names.get(problem_type, problem_type)
                    
                    query = f"–ü–µ—á–∞—Ç—å {problem_name} –ø—Ä–∏ –ø–µ—á–∞—Ç–∏ {material} –Ω–∞ {printer}"
                    
                    if query not in seen_queries:
                        examples_from_article.append(query)
                
                # –ü—Ä–∏–º–µ—Ä 3: –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –æ –ø—Ä–æ–±–ª–µ–º–µ
                if problem_type and problem_type not in [ex.get("query", "") for ex in relevant_examples]:
                    problem_names = {
                        "stringing": "stringing",
                        "warping": "warping",
                        "layer_separation": "—Ç—Ä–µ—â–∏–Ω—ã –≤ —Å–ª–æ—è—Ö",
                        "bed_adhesion": "–ø—Ä–∏–ª–∏–ø–∞–Ω–∏–µ –∫ —Å—Ç–æ–ª—É",
                        "overhang": "–Ω–∞–≤–∏—Å–∞—é—â–∏–µ —á–∞—Å—Ç–∏",
                        "underextrusion": "–Ω–µ–¥–æ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ",
                        "overextrusion": "–ø–µ—Ä–µ–∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ"
                    }
                    problem_name = problem_names.get(problem_type, problem_type)
                    query = f"–ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã {problem_name}?"
                    
                    if query not in seen_queries:
                        examples_from_article.append(query)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã (–±—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏)
                for query in examples_from_article:
                    if len(relevant_examples) >= limit:
                        break
                    
                    # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
                    try:
                        results = await rag_service.hybrid_search(
                            query=query,
                            limit=1,
                            boost_filters=False
                        )
                        
                        if results and len(results) > 0:
                            score = results[0].get("score", 0.0)
                            if score >= min_score:
                                seen_queries.add(query)
                                relevant_examples.append({
                                    "query": query,
                                    "score": round(score, 2),
                                    "has_relevant_articles": True
                                })
                    except Exception as e:
                        logger.debug(f"Error checking generated query '{query[:50]}...': {e}")
                        # –í—Å–µ —Ä–∞–≤–Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –∏–∑ KB
                        seen_queries.add(query)
                        relevant_examples.append({
                            "query": query,
                            "score": 0.8,  # –°—Ä–µ–¥–Ω–∏–π score –¥–ª—è –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ KB
                            "has_relevant_articles": True
                        })
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score
        relevant_examples = sorted(relevant_examples, key=lambda x: x["score"], reverse=True)[:limit]
        
        logger.info(f"‚úÖ Generated {len(relevant_examples)} relevant examples")
        
        return {
            "examples": relevant_examples
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ========== ENDPOINTS –î–õ–Ø –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô ==========

@app.post("/api/diagnose", response_model=DiagnosticResponse)
async def diagnose_problem(request: DiagnosticRequest):
    """
    –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º—ã 3D-–ø–µ—á–∞—Ç–∏
    """
    try:
        if get_rag_service is None or get_llm_client is None:
            raise HTTPException(status_code=503, detail="–°–µ—Ä–≤–∏—Å—ã –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
        
        rag_service = get_rag_service()
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞
        if request.llm_provider and request.llm_model:
            # –í—Ä–µ–º–µ–Ω–Ω–æ –∏–∑–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            import os
            original_provider = os.environ.get("LLM_PROVIDER")
            original_model = None
            model_env_key = None
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–æ–≤—ã–µ
            original_timeout = None
            timeout_env_key = None
            
            if request.llm_provider == "openai":
                original_model = os.environ.get("OPENAI_MODEL")
                model_env_key = "OPENAI_MODEL"
                timeout_env_key = "OPENAI_TIMEOUT"
                original_timeout = os.environ.get("OPENAI_TIMEOUT")
                os.environ["LLM_PROVIDER"] = "openai"
                os.environ["OPENAI_MODEL"] = request.llm_model
                if request.llm_timeout:
                    os.environ["OPENAI_TIMEOUT"] = str(request.llm_timeout)
            elif request.llm_provider == "ollama":
                original_model = os.environ.get("OLLAMA_MODEL")
                model_env_key = "OLLAMA_MODEL"
                timeout_env_key = "OLLAMA_TIMEOUT"
                original_timeout = os.environ.get("OLLAMA_TIMEOUT")
                os.environ["LLM_PROVIDER"] = "ollama"
                os.environ["OLLAMA_MODEL"] = request.llm_model
                if request.llm_timeout:
                    os.environ["OLLAMA_TIMEOUT"] = str(request.llm_timeout)
            elif request.llm_provider == "gemini":
                original_model = os.environ.get("GEMINI_MODEL")
                model_env_key = "GEMINI_MODEL"
                timeout_env_key = "GEMINI_TIMEOUT"
                original_timeout = os.environ.get("GEMINI_TIMEOUT")
                os.environ["LLM_PROVIDER"] = "gemini"
                os.environ["GEMINI_MODEL"] = request.llm_model
                if request.llm_timeout:
                    os.environ["GEMINI_TIMEOUT"] = str(request.llm_timeout)
            
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–∏–Ω–≥–ª—Ç–æ–Ω –¥–ª—è –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å –Ω–æ–≤—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
            from services.llm_client import reset_llm_client
            reset_llm_client()
            
            try:
                llm_client = get_llm_client(provider=request.llm_provider)
            finally:
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                if original_provider:
                    os.environ["LLM_PROVIDER"] = original_provider
                else:
                    os.environ.pop("LLM_PROVIDER", None)
                
                if model_env_key:
                    if original_model:
                        os.environ[model_env_key] = original_model
                    else:
                        os.environ.pop(model_env_key, None)
                
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç
                if timeout_env_key:
                    if original_timeout:
                        os.environ[timeout_env_key] = original_timeout
                    else:
                        os.environ.pop(timeout_env_key, None)
                
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–∏–Ω–≥–ª—Ç–æ–Ω
                reset_llm_client()
        else:
            llm_client = get_llm_client()
        
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        filters = {}
        if request.problem_type:
            filters["problem_type"] = request.problem_type
        if request.printer_model:
            filters["printer_models"] = [request.printer_model]
        if request.material:
            filters["materials"] = [request.material]
        
        # –ü–æ–∏—Å–∫ –≤ KB
        search_results = await rag_service.hybrid_search(
            query=request.query,
            filters=filters if filters else None,
            limit=3,
            boost_filters=True
        )
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —É—Ç–æ—á–Ω–µ–Ω–∏–π
        needs_clarification = False
        clarification_questions = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        if not request.printer_model:
            needs_clarification = True
            clarification_questions.append(
                ClarificationQuestion(
                    question="–ö–∞–∫–∞—è —É –≤–∞—Å –º–æ–¥–µ–ª—å –ø—Ä–∏–Ω—Ç–µ—Ä–∞?",
                    question_type="printer_model",
                    options=None  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
                )
            )
        
        if not request.material:
            needs_clarification = True
            clarification_questions.append(
                ClarificationQuestion(
                    question="–ö–∞–∫–æ–π –º–∞—Ç–µ—Ä–∏–∞–ª –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ? (PLA, PETG, ABS, etc.)",
                    question_type="material",
                    options=["PLA", "PETG", "ABS", "TPU", "–î—Ä—É–≥–æ–µ"]
                )
            )
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞, –Ω–æ –∏—Ö –º–∞–ª–æ –∏–ª–∏ –Ω–∏–∑–∫–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
        if search_results and len(search_results) < 2:
            if search_results[0].get("score", 0) < 0.7:
                needs_clarification = True
                clarification_questions.append(
                    ClarificationQuestion(
                        question="–ú–æ–∂–µ—Ç–µ –æ–ø–∏—Å–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—É –ø–æ–¥—Ä–æ–±–Ω–µ–µ? –ß—Ç–æ –∏–º–µ–Ω–Ω–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç?",
                        question_type="symptom",
                        options=None
                    )
                )
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM
        context = ""
        if search_results:
            context = "\n\n".join([
                f"–°—Ç–∞—Ç—å—è: {r.get('title', '')}\n{r.get('content', '')[:500]}..."
                for r in search_results[:3]
            ])
        
        prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –ø—Ä–æ–±–ª–µ–º 3D-–ø–µ—á–∞—Ç–∏.

–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {request.query}
"""
        
        if request.printer_model:
            prompt += f"\n–ú–û–î–ï–õ–¨ –ü–†–ò–ù–¢–ï–†–ê: {request.printer_model}"
        
        if request.material:
            prompt += f"\n–ú–ê–¢–ï–†–ò–ê–õ: {request.material}"
        
        if context:
            prompt += f"\n\n–†–ï–õ–ï–í–ê–ù–¢–ù–´–ï –°–¢–ê–¢–¨–ò –ò–ó –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô:\n{context}"
        
        prompt += """

–ó–ê–î–ê–ß–ê:
1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
2. –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
3. –î–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞, —Å–∫–æ—Ä–æ—Å—Ç—å, retraction)
4. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ - —É–∫–∞–∂–∏, —á—Ç–æ –Ω—É–∂–Ω—ã —É—Ç–æ—á–Ω–µ–Ω–∏—è

–û–¢–í–ï–¢ –î–û–õ–ñ–ï–ù –ë–´–¢–¨:
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º (—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏)
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º (–ø—Ä–æ–±–ª–µ–º–∞ ‚Üí —Ä–µ—à–µ–Ω–∏–µ ‚Üí –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
- –ü–æ–Ω—è—Ç–Ω—ã–º –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- –°—Å—ã–ª–∫–∞–º–∏ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
"""
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–∞–π–º–∞—É—Ç –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        llm_timeout = None
        if request.llm_timeout:
            llm_timeout = request.llm_timeout
        elif request.llm_provider:
            # –ü–æ–ª—É—á–∞–µ–º —Ç–∞–π–º–∞—É—Ç –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
            import os
            if request.llm_provider == "ollama":
                llm_timeout = int(os.getenv("OLLAMA_TIMEOUT", "500"))
            elif request.llm_provider == "openai":
                llm_timeout = int(os.getenv("OPENAI_TIMEOUT", "600"))
            elif request.llm_provider == "gemini":
                llm_timeout = int(os.getenv("GEMINI_TIMEOUT", "600"))
        
        answer = await llm_client.generate(
            prompt=prompt,
            system_prompt="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –ø—Ä–æ–±–ª–µ–º 3D-–ø–µ—á–∞—Ç–∏. –û—Ç–≤–µ—á–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ.",
            timeout=llm_timeout
        )
        
        # –û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        confidence = 0.8 if search_results and search_results[0].get("score", 0) > 0.7 else 0.5
        
        return DiagnosticResponse(
            answer=answer,
            needs_clarification=needs_clarification,
            clarification_questions=clarification_questions if needs_clarification else None,
            relevant_articles=[
                {
                    "title": r.get("title", ""),
                    "url": r.get("url", ""),
                    "score": r.get("score", 0.0)
                }
                for r in search_results[:3]
            ] if search_results else None,
            confidence=confidence
        )
        
    except HTTPException:
        raise
    except ConnectionError as e:
        error_msg = str(e)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ —Ç–∞–π–º–∞—É—Ç–æ–º
        if "–Ω–µ –æ—Ç–≤–µ—Ç–∏–ª –≤ —Ç–µ—á–µ–Ω–∏–µ" in error_msg or "timeout" in error_msg.lower():
            logger.warning(f"‚è±Ô∏è –¢–∞–π–º–∞—É—Ç LLM –∑–∞–ø—Ä–æ—Å–∞: {e}")
            raise HTTPException(
                status_code=504,
                detail=(
                    f"–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM. {error_msg} "
                    "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–≤–µ–ª–∏—á–∏—Ç—å —Ç–∞–π–º–∞—É—Ç –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å."
                )
            )
        elif "ollama" in error_msg.lower() or "connection refused" in error_msg.lower():
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LLM —Å–µ—Ä–≤–∏—Å—É: {e}", exc_info=True)
            raise HTTPException(
                status_code=503,
                detail=(
                    "LLM —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. "
                    "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω (ollama serve) –∏–ª–∏ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –¥—Ä—É–≥–æ–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä (Gemini/OpenAI) –≤ config.env"
                )
            )
        else:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}", exc_info=True)
            raise HTTPException(status_code=503, detail=f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ —Å–µ—Ä–≤–∏—Å—É: {error_msg}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: {e}", exc_info=True)
        error_msg = str(e)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å–≤—è–∑–∞–Ω–∞ –ª–∏ –æ—à–∏–±–∫–∞ —Å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å—é LLM
        if "connection refused" in error_msg.lower() or "errno 111" in error_msg.lower():
            raise HTTPException(
                status_code=503,
                detail=(
                    "LLM —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. "
                    "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ LLM_PROVIDER –≤ config.env –∏ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä –∑–∞–ø—É—â–µ–Ω –∏ –¥–æ—Å—Ç—É–ø–µ–Ω."
                )
            )
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: {error_msg}")


@app.post("/api/diagnose/image", response_class=JSONResponse)
async def diagnose_with_image(
    query: str = Body(...),
    printer_model: Optional[str] = Body(None),
    material: Optional[str] = Body(None),
    problem_type: Optional[str] = Body(None),
    conversation_history: Optional[str] = Body(None),  # JSON —Å—Ç—Ä–æ–∫–∞
    image: UploadFile = File(...),
    use_reranking: Optional[str] = Body("true"),  # –°—Ç—Ä–æ–∫–∞ –∏–∑ form-data
    limit: Optional[str] = Body("5")  # –°—Ç—Ä–æ–∫–∞ –∏–∑ form-data
):
    """
    –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å –∞–Ω–∞–ª–∏–∑–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç–∞ —á–µ—Ä–µ–∑ RetrievalAgent
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç RetrievalAgent –¥–ª—è:
    1. –ê–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Vision Analyzer (Gemini/Ollama)
    2. –ò–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (problem_type, symptoms, description)
    3. –ü–æ–∏—Å–∫–∞ –≤ KB —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    4. –†–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    """
    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º RetrievalAgent
        try:
            from app.agents import get_retrieval_agent
        except ImportError:
            logger.error("RetrievalAgent –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            raise HTTPException(status_code=503, detail="RetrievalAgent –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        retrieval_agent = get_retrieval_agent()
        
        # –ß–∏—Ç–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_data = await image.read()
        
        # –î–µ—Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º conversation_history –∏–∑ JSON —Å—Ç—Ä–æ–∫–∏
        parsed_history = None
        if conversation_history:
            try:
                parsed_history = json.loads(conversation_history)
                if not isinstance(parsed_history, list):
                    parsed_history = None
            except (json.JSONDecodeError, TypeError) as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å conversation_history: {e}")
                parsed_history = None
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –Ω—É–∂–Ω—ã–µ —Ç–∏–ø—ã
        use_reranking_bool = use_reranking.lower() == "true" if isinstance(use_reranking, str) else bool(use_reranking)
        limit_int = int(limit) if isinstance(limit, str) else limit
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤
        filters = {}
        if problem_type:
            filters["problem_type"] = problem_type
        if printer_model:
            filters["printer_models"] = [printer_model]
        if material:
            filters["materials"] = [material]
        
        # –£–ª—É—á—à–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ —Å —É—á–µ—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞
        enhanced_query = query
        if parsed_history and len(parsed_history) > 0:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –∑–∞–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏
            previous_context = []
            for msg in conversation_history[-3:]:  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 —Å–æ–æ–±—â–µ–Ω–∏—è
                if isinstance(msg, dict):
                    role = msg.get("role", "")
                    content = msg.get("content", "")
                    if role == "user" and content:
                        previous_context.append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {content}")
                    elif role == "assistant" and content:
                        previous_context.append(f"–°–∏—Å—Ç–µ–º–∞: {content[:200]}...")  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
            
            if previous_context:
                context_text = "\n".join(previous_context)
                enhanced_query = f"{query}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞:\n{context_text}"
                logger.info(f"üìù –ó–∞–ø—Ä–æ—Å —É–ª—É—á—à–µ–Ω —Å —É—á–µ—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞ ({len(parsed_history)} —Å–æ–æ–±—â–µ–Ω–∏–π)")
        
        # –ü–æ–∏—Å–∫ —Å –∞–Ω–∞–ª–∏–∑–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ RetrievalAgent
        logger.info(f"üîç –ü–æ–∏—Å–∫ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º: query='{query}', filters={filters}, history_len={len(parsed_history) if parsed_history else 0}")
        
        search_results = await retrieval_agent.search_with_image(
            query=enhanced_query,
            image_data=image_data,
            filters=filters if filters else None,
            limit=limit_int,
            use_reranking=use_reranking_bool
        )
        
        # –ü–æ–ª—É—á–∞–µ–º LLM –∫–ª–∏–µ–Ω—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞
        if get_llm_client is None:
            raise HTTPException(status_code=503, detail="LLM —Å–µ—Ä–≤–∏—Å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        llm_client = get_llm_client()
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
        context = ""
        if search_results:
            # –ë–µ—Ä–µ–º —Ç–æ–ø-3 —Å—Ç–∞—Ç—å–∏ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            context_articles = search_results[:3]
            context_parts = []
            for i, article in enumerate(context_articles, 1):
                title = article.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
                content = article.get('content', '')
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 800 —Å–∏–º–≤–æ–ª–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                content_preview = content[:800] if len(content) > 800 else content
                if len(content) > 800:
                    content_preview += "..."
                
                article_text = f"–°—Ç–∞—Ç—å—è {i}: {title}\n{content_preview}"
                
                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å
                if article.get('problem_type'):
                    article_text += f"\n–¢–∏–ø –ø—Ä–æ–±–ª–µ–º—ã: {article.get('problem_type')}"
                if article.get('printer_models'):
                    article_text += f"\n–ü—Ä–∏–Ω—Ç–µ—Ä—ã: {', '.join(article.get('printer_models', []))}"
                if article.get('materials'):
                    article_text += f"\n–ú–∞—Ç–µ—Ä–∏–∞–ª—ã: {', '.join(article.get('materials', []))}"
                
                context_parts.append(article_text)
            
            context = "\n\n---\n\n".join(context_parts)
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è LLM
        prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –ø—Ä–æ–±–ª–µ–º 3D-–ø–µ—á–∞—Ç–∏. –¢—ã –ø–æ–º–æ–≥–∞–µ—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Ä–µ—à–∞—Ç—å –∏—Ö –ø—Ä–æ–±–ª–µ–º—ã —Å —ç–º–ø–∞—Ç–∏–µ–π –∏ –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º.

–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {query}
"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞, –µ—Å–ª–∏ –µ—Å—Ç—å
        if parsed_history and len(parsed_history) > 0:
            history_context = []
            for msg in parsed_history[-3:]:  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 —Å–æ–æ–±—â–µ–Ω–∏—è
                if isinstance(msg, dict):
                    role = msg.get("role", "")
                    content = msg.get("content", "")
                    if role == "user" and content:
                        history_context.append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ä–∞–Ω–µ–µ —Å–∫–∞–∑–∞–ª: {content}")
                    elif role == "assistant" and content:
                        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –∫—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –æ—Ç–≤–µ—Ç–∞
                        history_context.append(f"–†–∞–Ω–µ–µ –±—ã–ª–æ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ: {content[:150]}...")
            
            if history_context:
                prompt += f"\n\n–ö–û–ù–¢–ï–ö–°–¢ –ü–†–ï–î–´–î–£–©–ï–ì–û –î–ò–ê–õ–û–ì–ê:\n" + "\n".join(history_context)
        
        if printer_model:
            prompt += f"\n–ú–û–î–ï–õ–¨ –ü–†–ò–ù–¢–ï–†–ê: {printer_model}"
        
        if material:
            prompt += f"\n–ú–ê–¢–ï–†–ò–ê–õ: {material}"
        
        if problem_type:
            prompt += f"\n–¢–ò–ü –ü–†–û–ë–õ–ï–ú–´: {problem_type}"
        
        if context:
            prompt += f"\n\n–†–ï–õ–ï–í–ê–ù–¢–ù–´–ï –°–¢–ê–¢–¨–ò –ò–ó –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô:\n{context}"
        
        prompt += """

–ó–ê–î–ê–ß–ê:
–ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Å—Ç–∞—Ç–µ–π –≤—ã—à–µ, —á—Ç–æ–±—ã –¥–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é:
1. –ü–æ–Ω–∏–º–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã (—á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∏ –ø–æ—á–µ–º—É)
2. –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞, —Å–∫–æ—Ä–æ—Å—Ç—å, retraction –∏ —Ç.–¥.)
3. –ü–æ—à–∞–≥–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

–°–¢–ò–õ–¨ –û–¢–í–ï–¢–ê:
- –ë—É–¥—å —ç–º–ø–∞—Ç–∏—á–Ω—ã–º –∏ –ø–æ–Ω–∏–º–∞—é—â–∏–º (–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å—Ç–æ–ª–∫–Ω—É–ª—Å—è —Å –ø—Ä–æ–±–ª–µ–º–æ–π)
- –ò—Å–ø–æ–ª—å–∑—É–π "—Ç—ã" –≤–º–µ—Å—Ç–æ "–≤—ã" –¥–ª—è –±–æ–ª–µ–µ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–≥–æ —Ç–æ–Ω–∞
- –û–±—ä—è—Å–Ω—è–π –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º, –∏–∑–±–µ–≥–∞—è –∏–∑–ª–∏—à–Ω–µ–≥–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∂–∞—Ä–≥–æ–Ω–∞
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç: —Å–Ω–∞—á–∞–ª–∞ –æ–±—ä—è—Å–Ω–∏ –ø—Ä–æ–±–ª–µ–º—É, –ø–æ—Ç–æ–º –¥–∞–π —Ä–µ—à–µ–Ω–∏—è
- –£–∫–∞–∂–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä: "—É–º–µ–Ω—å—à–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –¥–æ 200¬∞C")
- –ï—Å–ª–∏ –Ω—É–∂–Ω–æ - –¥–∞–π –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Ä–µ—à–µ–Ω–∏—è

–í–ê–ñ–ù–û:
- –ù–ï –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ—á–∏—Å–ª—è–π —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç–∞—Ç—å–∏
- –ù–ï –∫–æ–ø–∏—Ä—É–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç–µ–π –¥–æ—Å–ª–æ–≤–Ω–æ
- –î–ê–ô —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π, –ø–æ–Ω—è—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Å—Ç–∞—Ç–µ–π
- –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Å—Ç–∞—Ç–µ–π –∫–∞–∫ –æ—Å–Ω–æ–≤—É, –Ω–æ —Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —Å–≤–æ–∏–º–∏ —Å–ª–æ–≤–∞–º–∏
"""
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM
        try:
            answer = await llm_client.generate(
                prompt=prompt,
                system_prompt="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –ø—Ä–æ–±–ª–µ–º 3D-–ø–µ—á–∞—Ç–∏. –û—Ç–≤–µ—á–∞–π —ç–º–ø–∞—Ç–∏—á–Ω–æ, –ø–æ–Ω—è—Ç–Ω–æ –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π.",
                timeout=600  # –¢–∞–π–º–∞—É—Ç –¥–ª—è LLM
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM: {e}")
            # Fallback: —Ñ–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–µ–π
            if search_results:
                top_article = search_results[0]
                answer = f"–ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π, –ø–æ—Ö–æ–∂–µ –Ω–∞ –ø—Ä–æ–±–ª–µ–º—É: {top_article.get('title', 'stringing')}. "
                if top_article.get('solutions'):
                    answer += "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: "
                    for sol in top_article.get('solutions', [])[:3]:
                        answer += f"{sol.get('description', '')}; "
            else:
                answer = "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–ø–∏—Å–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—É –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ."
        
        # –û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        confidence = 0.8 if search_results and search_results[0].get("score", 0) > 0.7 else 0.5
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —É—Ç–æ—á–Ω–µ–Ω–∏–π
        needs_clarification = False
        clarification_questions = []
        
        if not printer_model and not any(p in query.lower() for p in ["ender", "prusa", "anycubic", "–ø—Ä–∏–Ω—Ç–µ—Ä"]):
            needs_clarification = True
            clarification_questions.append({
                "question": "–ö–∞–∫–∞—è —É –≤–∞—Å –º–æ–¥–µ–ª—å –ø—Ä–∏–Ω—Ç–µ—Ä–∞?",
                "question_type": "printer_model",
                "options": None
            })
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ DiagnosticResponse
        return {
            "success": True,
            "answer": answer,
            "query": query,
            "image_name": image.filename,
            "image_size": len(image_data),
            "relevant_articles": search_results[:5],  # –¢–æ–ø-5 —Å—Ç–∞—Ç–µ–π –∫–∞–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            "results_count": len(search_results),
            "confidence": confidence,
            "needs_clarification": needs_clarification,
            "clarification_questions": clarification_questions if needs_clarification else None,
            "image_analysis": True
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º: {str(e)}")


# ========== –°–õ–£–ñ–ï–ë–ù–´–ï ENDPOINTS ==========

@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è API"""
    return {
        "status": "healthy",
        "version": "0.1.0"
    }


@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π endpoint"""
    return {
        "message": "3dtoday Diagnostic API",
        "version": "0.1.0",
        "endpoints": {
            "diagnose": "/api/diagnose",
            "kb_validate": "/api/kb/articles/validate",
            "kb_add": "/api/kb/articles/add",
            "kb_statistics": "/api/kb/statistics",
            "health": "/health"
        }
    }


if __name__ == "__main__":
    import uvicorn
    
    host = os.getenv("API_HOST", "0.0.0.0")
    port = int(os.getenv("API_PORT", "8000"))
    
    uvicorn.run(app, host=host, port=port, reload=True)

