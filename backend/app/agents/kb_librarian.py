"""
–ê–≥–µ–Ω—Ç-–±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç–∞—Ç–µ–π
–î–µ–ª–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞: –ø—Ä–æ–±–ª–µ–º—ã, –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è, —Å—Ä–∞–≤–Ω–µ–Ω–∏—è, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏
–ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏–µ –æ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤ KB —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
"""

import os
import logging
import json
import httpx
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
load_dotenv(dotenv_path=Path(__file__).resolve().parents[3] / "config.env")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å –∑–∞–ø–∏—Å—å—é –≤ —Ñ–∞–π–ª
try:
    from app.utils.logger_config import get_librarian_logger
    logger = get_librarian_logger()
except ImportError:
    # Fallback –µ—Å–ª–∏ logger_config –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    logger = logging.getLogger(__name__)
    if not logger.handlers:
        handler = logging.StreamHandler()
        handler.setFormatter(logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s"))
        logger.addHandler(handler)
        logger.setLevel(logging.INFO)


class KBLibrarianAgent:
    """
    –ê–≥–µ–Ω—Ç-–±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –¥–µ–ª–∞–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏–µ –æ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤ KB
    """
    
    def __init__(self, llm_provider: Optional[str] = None, model: Optional[str] = None, timeout: Optional[int] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞
        
        Args:
            llm_provider: –ü—Ä–æ–≤–∞–π–¥–µ—Ä LLM (openai, ollama, gemini). –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–∑ config.env
            model: –ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è. –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–∑ config.env
            timeout: –¢–∞–π–º–∞—É—Ç –¥–ª—è LLM –∑–∞–ø—Ä–æ—Å–æ–≤
        """
        self.llm_provider = llm_provider
        self.model = model
        self.timeout = timeout
        self.llm_client = None
        self.vector_db = None
        self._initialize_services()
    
    def _initialize_services(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–∏—Å–∏–º—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤"""
        try:
            # –ò–º–ø–æ—Ä—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø—É—Ç—è–º–∏
            import sys
            from pathlib import Path
            sys.path.insert(0, str(Path(__file__).resolve().parents[2]))
            
            try:
                from backend.app.services.llm_client import get_llm_client, reset_llm_client
                from backend.app.services.vector_db import get_vector_db
            except ImportError:
                from app.services.llm_client import get_llm_client, reset_llm_client
                from app.services.vector_db import get_vector_db
            
            # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –ø—Ä–æ–≤–∞–π–¥–µ—Ä –∏–ª–∏ –º–æ–¥–µ–ª—å, –≤—Ä–µ–º–µ–Ω–Ω–æ –º–µ–Ω—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
            original_provider = None
            original_model = None
            
            if self.llm_provider:
                original_provider = os.getenv("LLM_PROVIDER")
                os.environ["LLM_PROVIDER"] = self.llm_provider
            
            if self.model:
                if self.llm_provider == "openai":
                    original_model = os.getenv("OPENAI_MODEL")
                    os.environ["OPENAI_MODEL"] = self.model
                elif self.llm_provider == "ollama":
                    original_model = os.getenv("OLLAMA_MODEL")
                    os.environ["OLLAMA_MODEL"] = self.model
                elif self.llm_provider == "gemini":
                    original_model = os.getenv("GEMINI_MODEL")
                    os.environ["GEMINI_MODEL"] = self.model
            
            if self.timeout:
                if self.llm_provider == "openai":
                    os.environ["OPENAI_TIMEOUT"] = str(self.timeout)
                elif self.llm_provider == "ollama":
                    os.environ["OLLAMA_TIMEOUT"] = str(self.timeout)
                elif self.llm_provider == "gemini":
                    os.environ["GEMINI_TIMEOUT"] = str(self.timeout)
            
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–∏–Ω–≥–ª—Ç–æ–Ω, —á—Ç–æ–±—ã –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å –Ω–æ–≤—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
            if self.llm_provider:
                reset_llm_client()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ–∑–∂–µ
            self._original_provider = original_provider
            self._original_model = original_model
            self._original_provider_name = self.llm_provider
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–º –Ω–∞–ø—Ä—è–º—É—é
            # –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –Ω—É–∂–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä, –∞ –Ω–µ Ollama
            self.llm_client = get_llm_client(provider=self.llm_provider)
            self.vector_db = get_vector_db()
            
            # –í–ê–ñ–ù–û: –ù–ï –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ä–∞–∑—É!
            # –û–Ω–∏ –±—É–¥—É—Ç –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞
            # –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –∫–ª–∏–µ–Ω—Ç –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä
            
            logger.info(f"‚úÖ KBLibrarianAgent –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (provider={self.llm_provider or 'default'}, model={self.model or 'default'})")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ KBLibrarianAgent: {e}")
            raise
    
    async def review_and_decide(
        self,
        title: str,
        content: str,
        images: Optional[List[Dict[str, Any]]] = None,
        url: Optional[str] = None,
        content_type: Optional[str] = None,
        is_questions_list: bool = False
    ) -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª: –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞, –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ, –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
        
        Args:
            is_questions_list: True –µ—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–æ —Å–ø–∏—Å–∫–æ–º –≤–æ–ø—Ä–æ—Å–æ–≤ (–Ω–µ –¥–æ–±–∞–≤–ª—è—Ç—å –≤ KB)
        
        Returns:
            {
                "decision": "approve|reject|needs_review",
                "reason": "–ø—Ä–∏—á–∏–Ω–∞ —Ä–µ—à–µ–Ω–∏—è",
                "relevance_score": 0.0-1.0,
                "duplicate_check": {...},
                "abstract": "–∫—Ä–∞—Ç–∫–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ",
                "summary": {...},
                "recommendations": [...]
            }
        """
        try:
            # –ï—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤ - —Å—Ä–∞–∑—É –æ—Ç–∫–ª–æ–Ω—è–µ–º
            if is_questions_list:
                return {
                    "decision": "reject",
                    "reason": "–≠—Ç–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–æ —Å–ø–∏—Å–∫–æ–º –≤–æ–ø—Ä–æ—Å–æ–≤, –∞ –Ω–µ –æ—Ç–¥–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç—å—è. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ URL –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ KB.",
                    "relevance_score": 0.0,
                    "quality_score": 0.0,
                    "duplicate_check": {"is_duplicate": False},
                    "abstract": "",
                    "summary": {},
                    "filtered_content": "",
                    "recommendations": ["–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ URL –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –∏–∑ —Å–ø–∏—Å–∫–∞"]
                }
            # –®–∞–≥ 1: –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            summary = await self.analyze_article(
                title=title,
                content=content,
                images=images,
                url=url,
                content_type=content_type
            )
            
            # –®–∞–≥ 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞
            relevance_check = await self._check_relevance(title, content, summary)
            
            # –®–∞–≥ 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
            duplicate_check = await self._check_duplicates(title, content, summary)
            
            # –®–∞–≥ 4: –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ abstract
            abstract = await self._create_abstract(title, content, summary)
            
            # –®–∞–≥ 5: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–µ—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            filtered_content = await self._filter_irrelevant_content(content, summary)
            
            # –®–∞–≥ 6: –ü—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è
            decision = await self._make_decision(
                relevance_check=relevance_check,
                duplicate_check=duplicate_check,
                summary=summary,
                abstract=abstract
            )
            
            return {
                "decision": decision["decision"],
                "reason": decision["reason"],
                "relevance_score": relevance_check.get("score", 0.0),
                "quality_score": relevance_check.get("quality_score", 0.0),
                "duplicate_check": duplicate_check,
                "abstract": abstract,
                "summary": summary,
                "filtered_content": filtered_content,
                "recommendations": decision.get("recommendations", []),
                "key_points": summary.get("key_points", [])
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è: {e}", exc_info=True)
            return {
                "decision": "needs_review",
                "reason": f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}",
                "relevance_score": 0.0,
                "duplicate_check": {"is_duplicate": False},
                "abstract": "",
                "summary": {},
                "filtered_content": content[:500] + "...",
                "recommendations": ["–¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞"]
            }
    
    async def _check_relevance(
        self,
        title: str,
        content: str,
        summary: Dict[str, Any]
    ) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        prompt = f"""–¢—ã - –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å KB –ø–æ 3D-–ø–µ—á–∞—Ç–∏ –∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –ø—Ä–æ–±–ª–µ–º.

–û—Ü–µ–Ω–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ KB.

–ó–ê–ì–û–õ–û–í–û–ö: {title}

–°–û–î–ï–†–ñ–ê–ù–ò–ï (–ø–µ—Ä–≤—ã–µ 2000 —Å–∏–º–≤–æ–ª–æ–≤):
{content[:2000]}

–ê–ù–ê–õ–ò–ó –î–û–ö–£–ú–ï–ù–¢–ê:
{json.dumps(summary, ensure_ascii=False, indent=2)[:1000]}

–ö–†–ò–¢–ï–†–ò–ò –û–¶–ï–ù–ö–ò:
1. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ç–µ–º–∞—Ç–∏–∫–µ 3D-–ø–µ—á–∞—Ç–∏ (0.0-1.0)
   ‚úÖ –†–ï–õ–ï–í–ê–ù–¢–ù–´:
   - –°—Ç–∞—Ç—å–∏ –æ –ø—Ä–æ–±–ª–µ–º–∞—Ö 3D-–ø–µ—á–∞—Ç–∏ –∏ –∏—Ö —Ä–µ—à–µ–Ω–∏—è—Ö
   - –û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –æ 3D-–ø—Ä–∏–Ω—Ç–µ—Ä–∞—Ö, –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö
   - –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ
   - –°—Ä–∞–≤–Ω–µ–Ω–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤, –ø—Ä–∏–Ω—Ç–µ—Ä–æ–≤, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π
   - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
   - –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è 3D-–ø–µ—á–∞—Ç–∏
   - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–∞—Å—Ö–æ–¥–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö (—Ñ–∏–ª–∞–º–µ–Ω—Ç–∞—Ö)
   
   ‚ùå –ù–ï –†–ï–õ–ï–í–ê–ù–¢–ù–´:
   - –û–±—Å—É–∂–¥–µ–Ω–∏—è –º—É–∑—ã–∫–∏, –ª–∏—á–Ω—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è, –æ—Ñ—Ñ—Ç–æ–ø
   - –ö–æ–Ω—Ç–µ–Ω—Ç –Ω–µ —Å–≤—è–∑–∞–Ω–Ω—ã–π —Å 3D-–ø–µ—á–∞—Ç—å—é
   - –ß–∏—Å—Ç–æ —Ä–∞–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –±–µ–∑ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏

2. –ö–∞—á–µ—Å—Ç–≤–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (–∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ—Å—Ç—å, —Ç–æ—á–Ω–æ—Å—Ç—å) (0.0-1.0)
   - –î–ª—è —Å—Ç–∞—Ç–µ–π –æ –ø—Ä–æ–±–ª–µ–º–∞—Ö: –µ—Å—Ç—å –ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ —Ä–µ—à–µ–Ω–∏—è?
   - –î–ª—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π: —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∏ –ø–æ–ª–Ω–æ—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
   - –î–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: —Ç–æ—á–Ω–æ—Å—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
   - –î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏–π: –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏ –¥–µ—Ç–∞–ª—å–Ω–æ—Å—Ç—å

3. –ù–∞–ª–∏—á–∏–µ –ø–æ–ª–µ–∑–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
   - –†–µ—à–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º –ø–µ—á–∞—Ç–∏ (–¥–ª—è —Å—Ç–∞—Ç–µ–π –æ –ø—Ä–æ–±–ª–µ–º–∞—Ö)
   - –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
   - –û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å (–¥–ª—è –æ–±—â–∏—Ö —Å—Ç–∞—Ç–µ–π)
   - –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å

4. –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ "–≤–æ–¥—ã" –∏ –Ω–µ—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
   - –ù–µ—Ç –ª–∏—à–Ω–∏—Ö –æ–±—Å—É–∂–¥–µ–Ω–∏–π
   - –§–æ–∫—É—Å –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π/–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏

–í–ê–ñ–ù–û: 
- –û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –æ 3D-–ø–µ—á–∞—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ß—Ç–æ —Ç–∞–∫–æ–µ 3D-–ø—Ä–∏–Ω—Ç–µ—Ä") –†–ï–õ–ï–í–ê–ù–¢–ù–´ –∏ –¥–æ–ª–∂–Ω—ã –ø–æ–ª—É—á–∞—Ç—å –≤—ã—Å–æ–∫—É—é –æ—Ü–µ–Ω–∫—É (>= 0.7)
- –°—Ç–∞—Ç—å–∏ –∏–∑ –≤–∏–∫–∏–ø–µ–¥–∏–∏ 3D-–ø–µ—á–∞—Ç–∏ –†–ï–õ–ï–í–ê–ù–¢–ù–´
- –û—Ç–∫–ª–æ–Ω—è–π —Ç–æ–ª—å–∫–æ –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–µ —Å–≤—è–∑–∞–Ω–Ω—ã–π —Å 3D-–ø–µ—á–∞—Ç—å—é

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON:
{{
    "score": 0.0-1.0,
    "quality_score": 0.0-1.0,
    "is_relevant": true/false,
    "has_valuable_info": true/false,
    "issues": ["–ø—Ä–æ–±–ª–µ–º–∞1", "–ø—Ä–æ–±–ª–µ–º–∞2"] –∏–ª–∏ [],
    "strengths": ["—Å–∏–ª—å–Ω–∞—è —Å—Ç–æ—Ä–æ–Ω–∞1"] –∏–ª–∏ []
}}
"""
        
        try:
            response = await self.llm_client.generate(
                prompt=prompt,
                system_prompt="–¢—ã —Å—Ç—Ä–æ–≥–∏–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å. –û—Ü–µ–Ω–∏–≤–∞–π –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ –∏ –∫—Ä–∏—Ç–∏—á–Ω–æ. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON."
            )
            
            json_data = self._extract_json(response)
            if json_data:
                return json_data
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏: {e}", exc_info=True)
        
        # Fallback
        return {
            "score": 0.5,
            "quality_score": 0.5,
            "is_relevant": True,
            "has_valuable_info": True,
            "issues": [],
            "strengths": []
        }
    
    async def _check_duplicates(
        self,
        title: str,
        content: str,
        summary: Dict[str, Any]
    ) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ KB"""
        try:
            # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ KB
            from app.services.rag_service import get_rag_service
            
            rag_service = get_rag_service()
            
            # –ü–æ–∏—Å–∫ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É –∏ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            search_query = f"{title} {summary.get('problem', '')} {', '.join(summary.get('printer_models', []))}"
            
            similar_docs = await rag_service.search(
                query=search_query,
                limit=5
            )
            
            if not similar_docs:
                return {
                    "is_duplicate": False,
                    "similar_docs": [],
                    "similarity_scores": []
                }
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ —á–µ—Ä–µ–∑ LLM
            similar_titles = [doc.get("title", "") for doc in similar_docs[:3]]
            similar_scores = [doc.get("score", 0.0) for doc in similar_docs[:3]]
            
            prompt = f"""–ü—Ä–æ–≤–µ—Ä—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –Ω–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≤ KB.

–ù–û–í–´–ô –î–û–ö–£–ú–ï–ù–¢:
–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}
–ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã: {', '.join(summary.get('key_points', [])[:5])}

–°–£–©–ï–°–¢–í–£–Æ–©–ò–ï –î–û–ö–£–ú–ï–ù–¢–´ –í KB:
{chr(10).join(f"{i+1}. {title}" for i, title in enumerate(similar_titles))}

–û–¶–ï–ù–ö–ò –ü–û–•–û–ñ–ï–°–¢–ò (–≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫):
{', '.join(f"{score:.2f}" for score in similar_scores)}

–ó–ê–î–ê–ß–ê:
–û–ø—Ä–µ–¥–µ–ª–∏, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –Ω–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–º –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —É–Ω–∏–∫–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON:
{{
    "is_duplicate": true/false,
    "duplicate_reason": "–ø—Ä–∏—á–∏–Ω–∞" –∏–ª–∏ null,
    "uniqueness": "—á—Ç–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –≤ –Ω–æ–≤–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ" –∏–ª–∏ null,
    "recommendation": "approve|reject|merge"
}}
"""
            
            response = await self.llm_client.generate(
                prompt=prompt,
                system_prompt="–¢—ã –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å. –û–ø—Ä–µ–¥–µ–ª—è–π –¥—É–±–ª–∏–∫–∞—Ç—ã —Å—Ç—Ä–æ–≥–æ. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON."
            )
            
            json_data = self._extract_json(response)
            
            return {
                "is_duplicate": json_data.get("is_duplicate", False) if json_data else False,
                "duplicate_reason": json_data.get("duplicate_reason") if json_data else None,
                "uniqueness": json_data.get("uniqueness") if json_data else None,
                "recommendation": json_data.get("recommendation", "approve") if json_data else "approve",
                "similar_docs": similar_titles,
                "similarity_scores": similar_scores
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ: {e}", exc_info=True)
            return {
                "is_duplicate": False,
                "similar_docs": [],
                "similarity_scores": []
            }
    
    async def _create_abstract(
        self,
        title: str,
        content: str,
        summary: Dict[str, Any]
    ) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ abstract –±–µ–∑ –≤–æ–¥—ã"""
        content_type = summary.get("content_type", "article")
        
        # –£–ø—Ä–æ—â–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        key_points = summary.get('key_points', [])[:5]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 5 –ø—É–Ω–∫—Ç–æ–≤
        key_points_text = chr(10).join(f"- {kp}" for kp in key_points) if key_points else "–ù–µ —É–∫–∞–∑–∞–Ω—ã"
        
        prompt = f"""–°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–∏–π abstract (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –¥–ª—è —Å—Ç–∞—Ç—å–∏:

–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}
–¢–∏–ø: {content_type}
–ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã:
{key_points_text}

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: —Ç–æ–ª—å–∫–æ —Ñ–∞–∫—Ç—ã, –±–µ–∑ –≤–æ–¥—ã, –ø—Ä–æ 3D-–ø–µ—á–∞—Ç—å.

Abstract:"""
        
        try:
            abstract = await self.llm_client.generate(
                prompt=prompt,
                system_prompt="–¢—ã –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å. –°–æ–∑–¥–∞–≤–∞–π –∫—Ä–∞—Ç–∫–∏–µ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ abstract –±–µ–∑ –≤–æ–¥—ã. –¢–æ–ª—å–∫–æ —Ñ–∞–∫—Ç—ã."
            )
            
            # –û—á–∏—Å—Ç–∫–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            abstract = abstract.strip()
            if abstract.startswith('"') and abstract.endswith('"'):
                abstract = abstract[1:-1]
            
            return abstract[:500]  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è abstract: {e}", exc_info=True)
            # Fallback
            return f"{title}. {summary.get('problem', '') or summary.get('summary', '')[:200]}..."
    
    async def _filter_irrelevant_content(
        self,
        content: str,
        summary: Dict[str, Any]
    ) -> str:
        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–µ—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        prompt = f"""–¢—ã - –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å KB. –û—Ç—Ñ–∏–ª—å—Ç—Ä—É–π –Ω–µ—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞.

–ò–°–•–û–î–ù–´–ô –ö–û–ù–¢–ï–ù–¢:
{content[:3000]}

–ö–õ–Æ–ß–ï–í–´–ï –ú–û–ú–ï–ù–¢–´ (—á—Ç–æ –≤–∞–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å):
{chr(10).join(f"- {kp}" for kp in summary.get('key_points', [])[:10])}

–ó–ê–î–ê–ß–ê:
–°–æ–∑–¥–∞–π –≤–µ—Ä—Å–∏—é –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ë–ï–ó:
- –í–æ–¥—ã –∏ –æ–±—â–∏—Ö —Ñ—Ä–∞–∑
- –†–µ–∫–ª–∞–º—ã –∏ –ø—Ä–æ–º–æ-–º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤
- –ù–µ—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π
- –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤–Ω–µ —Ç–µ–º–∞—Ç–∏–∫–∏ 3D-–ø–µ—á–∞—Ç–∏

–°–æ—Ö—Ä–∞–Ω–∏ –¢–û–õ–¨–ö–û:
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–∫—Ç—ã
- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∑–Ω–∞—á–µ–Ω–∏—è
- –†–µ—à–µ–Ω–∏—è –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏

–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç:
"""
        
        try:
            filtered = await self.llm_client.generate(
                prompt=prompt,
                system_prompt="–¢—ã –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å. –§–∏–ª—å—Ç—Ä—É–π —Å—Ç—Ä–æ–≥–æ. –£–±–∏—Ä–∞–π –≤–æ–¥—É, –æ—Å—Ç–∞–≤–ª—è–π —Ç–æ–ª—å–∫–æ —Ñ–∞–∫—Ç—ã."
            )
            
            return filtered[:5000]  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {e}", exc_info=True)
            return content[:2000] + "..."  # Fallback
    
    async def _make_decision(
        self,
        relevance_check: Dict[str, Any],
        duplicate_check: Dict[str, Any],
        summary: Dict[str, Any],
        abstract: str
    ) -> Dict[str, Any]:
        """–ü—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"""
        
        relevance_score = relevance_check.get("score", 0.0)
        quality_score = relevance_check.get("quality_score", 0.0)
        is_relevant = relevance_check.get("is_relevant", False)
        has_valuable_info = relevance_check.get("has_valuable_info", False)
        is_duplicate = duplicate_check.get("is_duplicate", False)
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –ø—Ä–∏–Ω—è—Ç–∏—è
        if is_duplicate:
            return {
                "decision": "reject",
                "reason": f"–î–æ–∫—É–º–µ–Ω—Ç —è–≤–ª—è–µ—Ç—Å—è –¥—É–±–ª–∏–∫–∞—Ç–æ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –≤ KB. {duplicate_check.get('duplicate_reason', '')}",
                "recommendations": [
                    "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ KB",
                    duplicate_check.get("recommendation", "reject") == "merge" and "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è" or None
                ]
            }
        
        if not is_relevant or relevance_score < 0.6:
            return {
                "decision": "reject",
                "reason": f"–î–æ–∫—É–º–µ–Ω—Ç –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω —Ç–µ–º–∞—Ç–∏–∫–µ KB (score: {relevance_score:.2f}). {', '.join(relevance_check.get('issues', []))}",
                "recommendations": relevance_check.get("issues", [])
            }
        
        if not has_valuable_info or quality_score < 0.6:
            return {
                "decision": "reject",
                "reason": f"–î–æ–∫—É–º–µ–Ω—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ü–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (quality: {quality_score:.2f}). {', '.join(relevance_check.get('issues', []))}",
                "recommendations": relevance_check.get("issues", [])
            }
        
        if relevance_score >= 0.7 and quality_score >= 0.7 and not is_duplicate:
            return {
                "decision": "approve",
                "reason": f"–î–æ–∫—É–º–µ–Ω—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–µ–Ω (relevance: {relevance_score:.2f}, quality: {quality_score:.2f}). {', '.join(relevance_check.get('strengths', []))}",
                "recommendations": ["–ì–æ—Ç–æ–≤ –∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤ KB"]
            }
        
        # –¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        return {
            "decision": "needs_review",
            "reason": f"–¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (relevance: {relevance_score:.2f}, quality: {quality_score:.2f})",
            "recommendations": [
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –≤—Ä—É—á–Ω—É—é",
                "–£–±–µ–¥–∏—Ç–µ—Å—å –≤ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è",
                *relevance_check.get("issues", [])
            ]
        }
    
    async def analyze_article(
        self,
        title: str,
        content: str,
        images: Optional[List[Dict[str, Any]]] = None,
        url: Optional[str] = None,
        content_type: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–≥–æ –∏–∑–ª–æ–∂–µ–Ω–∏—è
        
        Args:
            title: –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            images: –°–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏
            url: URL –¥–æ–∫—É–º–µ–Ω—Ç–∞
            content_type: –¢–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (article, documentation, comparison, technical)
        
        Returns:
            –ö—Ä–∞—Ç–∫–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ —Å –ø—Ä–æ–±–ª–µ–º–æ–π –∏ —Ä–µ—à–µ–Ω–∏–µ–º
        """
        try:
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω
            if not content_type:
                content_type = self._detect_content_type(title, content)
            
            # –ê–Ω–∞–ª–∏–∑ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            if content_type == "documentation":
                return await self._analyze_documentation(title, content, images, url)
            elif content_type == "comparison":
                return await self._analyze_comparison(title, content, images, url)
            elif content_type == "technical":
                return await self._analyze_technical(title, content, images, url)
            else:  # article (—Ä–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º)
                return await self._analyze_problem_article(title, content, images, url)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}", exc_info=True)
            return self._create_simple_summary(title, content, content_type)
    
    def _detect_content_type(self, title: str, content: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        text = (title + " " + content[:500]).lower()
        
        if any(kw in text for kw in ["–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è", "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è", "—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ", "manual"]):
            return "documentation"
        elif any(kw in text for kw in ["—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ", "vs", "versus", "—Ä–∞–∑–Ω–∏—Ü–∞"]):
            return "comparison"
        elif any(kw in text for kw in ["—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏", "–ø–∞—Ä–∞–º–µ—Ç—Ä—ã", "specs"]):
            return "technical"
        else:
            return "article"
    
    async def _analyze_problem_article(
        self,
        title: str,
        content: str,
        images: Optional[List[Dict[str, Any]]],
        url: Optional[str]
    ) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç—å–∏ –æ —Ä–µ—à–µ–Ω–∏–∏ –ø—Ä–æ–±–ª–µ–º (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞)"""
        text_summary = await self._analyze_text(title, content, content_type="article")
        
        image_analysis = None
        if images:
            image_analysis = await self._analyze_images(images)
        
        summary = await self._create_summary(
            title=title,
            text_analysis=text_summary,
            image_analysis=image_analysis,
            url=url,
            content_type="article"
        )
        
        return summary
    
    async def _analyze_documentation(
        self,
        title: str,
        content: str,
        images: Optional[List[Dict[str, Any]]],
        url: Optional[str]
    ) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è"""
        prompt = f"""–¢—ã - —É–º–Ω—ã–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ 3D-–ø—Ä–∏–Ω—Ç–µ—Ä–æ–≤.

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –∏ —Å–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ.

–ó–ê–ì–û–õ–û–í–û–ö: {title}

–°–û–î–ï–†–ñ–ê–ù–ò–ï:
{content[:4000]}

–ó–ê–î–ê–ß–ê:
1. –û–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ (–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è, —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è, —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ)
2. –í—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è
3. –ü–µ—Ä–µ—á–∏—Å–ª–∏ –≤–∞–∂–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
4. –£–∫–∞–∂–∏ –º–æ–¥–µ–ª–∏ –ø—Ä–∏–Ω—Ç–µ—Ä–æ–≤/–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON:
{{
    "documentation_type": "instruction" –∏–ª–∏ "specification" –∏–ª–∏ "manual",
    "equipment_models": ["Ender-3", ...] –∏–ª–∏ [],
    "key_specifications": {{
        "parameter1": "–∑–Ω–∞—á–µ–Ω–∏–µ1",
        "parameter2": "–∑–Ω–∞—á–µ–Ω–∏–µ2"
    }},
    "important_settings": ["–Ω–∞—Å—Ç—Ä–æ–π–∫–∞1", "–Ω–∞—Å—Ç—Ä–æ–π–∫–∞2"],
    "key_points": ["–∫–ª—é—á–µ–≤–æ–π –º–æ–º–µ–Ω—Ç 1", "–∫–ª—é—á–µ–≤–æ–π –º–æ–º–µ–Ω—Ç 2"]
}}
"""
        
        try:
            response = await self.llm_client.generate(
                prompt=prompt,
                system_prompt="–¢—ã —É–º–Ω—ã–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON."
            )
            
            json_data = self._extract_json(response)
            if json_data:
                summary_text = f"""**–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:** {json_data.get('documentation_type', 'unknown')}

**–ú–æ–¥–µ–ª–∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è:**
{chr(10).join(f"- {m}" for m in json_data.get('equipment_models', []))}

**–ö–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:**
{chr(10).join(f"- {k}: {v}" for k, v in json_data.get('key_specifications', {}).items())}

**–í–∞–∂–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:**
{chr(10).join(f"- {s}" for s in json_data.get('important_settings', []))}

**–ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã:**
{chr(10).join(f"- {kp}" for kp in json_data.get('key_points', []))}
"""
                
                return {
                    "title": title,
                    "url": url,
                    "summary": summary_text,
                    "content_type": "documentation",
                    "documentation_type": json_data.get("documentation_type"),
                    "equipment_models": json_data.get("equipment_models", []),
                    "key_specifications": json_data.get("key_specifications", {}),
                    "important_settings": json_data.get("important_settings", []),
                    "key_points": json_data.get("key_points", [])
                }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: {e}")
        
        return self._create_simple_summary(title, content, "documentation")
    
    async def _analyze_comparison(
        self,
        title: str,
        content: str,
        images: Optional[List[Dict[str, Any]]],
        url: Optional[str]
    ) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (–º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤, –ø—Ä–∏–Ω—Ç–µ—Ä–æ–≤, etc.)"""
        prompt = f"""–¢—ã - —É–º–Ω—ã–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è—Ö –≤ –æ–±–ª–∞—Å—Ç–∏ 3D-–ø–µ—á–∞—Ç–∏.

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏ —Å–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ.

–ó–ê–ì–û–õ–û–í–û–ö: {title}

–°–û–î–ï–†–ñ–ê–ù–ò–ï:
{content[:4000]}

–ó–ê–î–ê–ß–ê:
1. –û–ø—Ä–µ–¥–µ–ª–∏ —á—Ç–æ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç—Å—è (–º–∞—Ç–µ—Ä–∏–∞–ª—ã, –ø—Ä–∏–Ω—Ç–µ—Ä—ã, –Ω–∞—Å—Ç—Ä–æ–π–∫–∏)
2. –í—ã–¥–µ–ª–∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
3. –ü–µ—Ä–µ—á–∏—Å–ª–∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
4. –£–∫–∞–∂–∏ –∫–ª—é—á–µ–≤—ã–µ –æ—Ç–ª–∏—á–∏—è –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON:
{{
    "comparison_type": "materials" –∏–ª–∏ "printers" –∏–ª–∏ "settings" –∏–ª–∏ "other",
    "compared_items": ["–≤–∞—Ä–∏–∞–Ω—Ç1", "–≤–∞—Ä–∏–∞–Ω—Ç2"],
    "comparison_criteria": ["–∫—Ä–∏—Ç–µ—Ä–∏–π1", "–∫—Ä–∏—Ç–µ—Ä–∏–π2"],
    "key_differences": {{
        "–≤–∞—Ä–∏–∞–Ω—Ç1": ["–æ—Ç–ª–∏—á–∏–µ1", "–æ—Ç–ª–∏—á–∏–µ2"],
        "–≤–∞—Ä–∏–∞–Ω—Ç2": ["–æ—Ç–ª–∏—á–∏–µ1", "–æ—Ç–ª–∏—á–∏–µ2"]
    }},
    "recommendations": ["—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è1", "—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è2"],
    "key_points": ["–∫–ª—é—á–µ–≤–æ–π –º–æ–º–µ–Ω—Ç 1"]
}}
"""
        
        try:
            response = await self.llm_client.generate(
                prompt=prompt,
                system_prompt="–¢—ã —É–º–Ω—ã–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON."
            )
            
            json_data = self._extract_json(response)
            if json_data:
                summary_text = f"""**–¢–∏–ø —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:** {json_data.get('comparison_type', 'unknown')}

**–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã:**
{chr(10).join(f"- {item}" for item in json_data.get('compared_items', []))}

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:**
{chr(10).join(f"- {c}" for c in json_data.get('comparison_criteria', []))}

**–ö–ª—é—á–µ–≤—ã–µ –æ—Ç–ª–∏—á–∏—è:**
{chr(10).join(f"- **{item}**: {', '.join(diffs)}" for item, diffs in json_data.get('key_differences', {}).items())}

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
{chr(10).join(f"- {r}" for r in json_data.get('recommendations', []))}
"""
                
                return {
                    "title": title,
                    "url": url,
                    "summary": summary_text,
                    "content_type": "comparison",
                    "comparison_type": json_data.get("comparison_type"),
                    "compared_items": json_data.get("compared_items", []),
                    "comparison_criteria": json_data.get("comparison_criteria", []),
                    "key_differences": json_data.get("key_differences", {}),
                    "recommendations": json_data.get("recommendations", []),
                    "key_points": json_data.get("key_points", [])
                }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è: {e}")
        
        return self._create_simple_summary(title, content, "comparison")
    
    async def _analyze_technical(
        self,
        title: str,
        content: str,
        images: Optional[List[Dict[str, Any]]],
        url: Optional[str]
    ) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π"""
        prompt = f"""–¢—ã - —É–º–Ω—ã–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª—è—Ö 3D-–ø–µ—á–∞—Ç–∏.

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ —Å–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ.

–ó–ê–ì–û–õ–û–í–û–ö: {title}

–°–û–î–ï–†–ñ–ê–ù–ò–ï:
{content[:4000]}

–ó–ê–î–ê–ß–ê:
1. –û–ø—Ä–µ–¥–µ–ª–∏ —Ç–µ–º—É (–º–∞—Ç–µ—Ä–∏–∞–ª—ã, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–µ—á–∞—Ç–∏)
2. –í—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
3. –ü–µ—Ä–µ—á–∏—Å–ª–∏ –≤–∞–∂–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∏—Ö –∑–Ω–∞—á–µ–Ω–∏—è
4. –£–∫–∞–∂–∏ –æ–±–ª–∞—Å—Ç–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON:
{{
    "topic": "–º–∞—Ç–µ—Ä–∏–∞–ª—ã" –∏–ª–∏ "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏" –∏–ª–∏ "–ø–∞—Ä–∞–º–µ—Ç—Ä—ã",
    "key_characteristics": {{
        "—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞1": "–∑–Ω–∞—á–µ–Ω–∏–µ1",
        "—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞2": "–∑–Ω–∞—á–µ–Ω–∏–µ2"
    }},
    "important_parameters": ["–ø–∞—Ä–∞–º–µ—Ç—Ä1", "–ø–∞—Ä–∞–º–µ—Ç—Ä2"],
    "applications": ["–ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ1", "–ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ2"],
    "key_points": ["–∫–ª—é—á–µ–≤–æ–π –º–æ–º–µ–Ω—Ç 1"]
}}
"""
        
        try:
            response = await self.llm_client.generate(
                prompt=prompt,
                system_prompt="–¢—ã —É–º–Ω—ã–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON."
            )
            
            json_data = self._extract_json(response)
            if json_data:
                summary_text = f"""**–¢–µ–º–∞:** {json_data.get('topic', 'unknown')}

**–ö–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:**
{chr(10).join(f"- {k}: {v}" for k, v in json_data.get('key_characteristics', {}).items())}

**–í–∞–∂–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:**
{chr(10).join(f"- {p}" for p in json_data.get('important_parameters', []))}

**–û–±–ª–∞—Å—Ç–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è:**
{chr(10).join(f"- {a}" for a in json_data.get('applications', []))}
"""
                
                return {
                    "title": title,
                    "url": url,
                    "summary": summary_text,
                    "content_type": "technical",
                    "topic": json_data.get("topic"),
                    "key_characteristics": json_data.get("key_characteristics", {}),
                    "important_parameters": json_data.get("important_parameters", []),
                    "applications": json_data.get("applications", []),
                    "key_points": json_data.get("key_points", [])
                }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {e}")
        
        return self._create_simple_summary(title, content, "technical")
    
    async def _analyze_text(self, title: str, content: str, content_type: str = "article") -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–±–∞–∑–æ–≤–∞—è –ª–æ–≥–∏–∫–∞)"""
        prompt = f"""–¢—ã - —É–º–Ω—ã–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —Å—Ç–∞—Ç—å—è—Ö –æ 3D-–ø–µ—á–∞—Ç–∏.

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ç–∞—Ç—å—é –∏ —Å–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ.

–ó–ê–ì–û–õ–û–í–û–ö: {title}

–°–û–î–ï–†–ñ–ê–ù–ò–ï:
{content[:4000]}

–ó–ê–î–ê–ß–ê:
1. –û–ø—Ä–µ–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–Ω—É—é –ø—Ä–æ–±–ª–µ–º—É, –æ –∫–æ—Ç–æ—Ä–æ–π –∏–¥–µ—Ç —Ä–µ—á—å
2. –í—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Å–∏–º–ø—Ç–æ–º—ã
3. –ü–µ—Ä–µ—á–∏—Å–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
4. –£–∫–∞–∂–∏ –º–æ–¥–µ–ª–∏ –ø—Ä–∏–Ω—Ç–µ—Ä–æ–≤ –∏ –º–∞—Ç–µ—Ä–∏–∞–ª—ã (–µ—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è)

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:
{{
    "problem": "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)",
    "symptoms": ["—Å–∏–º–ø—Ç–æ–º1", "—Å–∏–º–ø—Ç–æ–º2"],
    "solutions": [
        {{
            "description": "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è",
            "parameters": {{
                "parameter1": "–∑–Ω–∞—á–µ–Ω–∏–µ1",
                "parameter2": "–∑–Ω–∞—á–µ–Ω–∏–µ2"
            }}
        }}
    ],
    "printer_models": ["Ender-3"] –∏–ª–∏ [],
    "materials": ["PLA"] –∏–ª–∏ [],
    "key_points": ["–∫–ª—é—á–µ–≤–æ–π –º–æ–º–µ–Ω—Ç 1", "–∫–ª—é—á–µ–≤–æ–π –º–æ–º–µ–Ω—Ç 2"]
}}
"""
        
        try:
            response = await self.llm_client.generate(
                prompt=prompt,
                system_prompt="–¢—ã —É–º–Ω—ã–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—å. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ç–∞—Ç—å–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ –∏ —Ç–æ—á–Ω–æ. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON."
            )
            
            return self._extract_json(response) or self._extract_simple_analysis(title, content)
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞: {e}")
            return self._extract_simple_analysis(title, content)
    
    def _extract_json(self, response: str) -> Optional[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM"""
        try:
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            if json_start >= 0 and json_end > json_start:
                json_str = response[json_start:json_end]
                return json.loads(json_str)
        except:
            pass
        return None
    
    async def _analyze_images(self, images: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """
        –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ —Å—Ç–∞—Ç—å–∏ —á–µ—Ä–µ–∑ Gemini Vision API
        –ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –∏–∑ ai_billing –ø—Ä–æ–µ–∫—Ç–∞
        """
        if not images:
            return None
        
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º VisionAnalyzer
            from app.services.vision_analyzer import VisionAnalyzer
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–æ–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            # –ï—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä - ollama, –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º llava
            prefer_ollama = (self.llm_provider or os.getenv("LLM_PROVIDER", "")).lower() == "ollama"
            vision_analyzer = VisionAnalyzer(prefer_ollama=prefer_ollama)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Vision API (Gemini –∏–ª–∏ Ollama/llava)
            availability = vision_analyzer.check_availability()
            if not availability.get('available', False):
                logger.warning(f"‚ö†Ô∏è Vision API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ({availability.get('provider', 'unknown')}): {availability.get('message', 'Unknown')}")
                # Fallback –Ω–∞ –∞–Ω–∞–ª–∏–∑ –æ–ø–∏—Å–∞–Ω–∏–π
                return await self._analyze_images_fallback(images)
            
            logger.info(f"üì∑ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {availability.get('provider', 'unknown')} –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Gemini Vision API
            image_analyses = []
            relevant_images = []
            
            for img_idx, img in enumerate(images[:10]):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                try:
                    # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å base64 –¥–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    image_data = img.get("data")
                    image_path = img.get("url")
                    image_name = img.get("title") or img.get("alt") or f"image_{img_idx + 1}"
                    
                    analysis_result = None
                    
                    # –ï—Å–ª–∏ –µ—Å—Ç—å base64 –¥–∞–Ω–Ω—ã–µ, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Ö
                    if image_data:
                        try:
                            analysis_result = vision_analyzer.analyze_image_from_base64(image_data, image_name)
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ base64 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image_name}: {e}")
                    
                    # –ï—Å–ª–∏ –µ—Å—Ç—å –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É, –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –µ–≥–æ
                    elif image_path and Path(image_path).exists():
                        try:
                            analysis_result = vision_analyzer.analyze_image_from_path(Path(image_path))
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞ {image_path}: {e}")
                    
                    # –ï—Å–ª–∏ –∞–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–µ–Ω, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                    if analysis_result and analysis_result.get('success'):
                        analysis_text = analysis_result.get('analysis', '')
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫ 3D-–ø–µ—á–∞—Ç–∏
                        relevance_result = vision_analyzer.check_relevance_to_3d_printing(analysis_text, image_name)
                        
                        if relevance_result.get('success') and relevance_result.get('is_relevant', False):
                            relevant_images.append({
                                'image_name': image_name,
                                'analysis': analysis_text,
                                'relevance_score': relevance_result.get('relevance_score', 0.5),
                                'problem_type': relevance_result.get('problem_type'),
                                'printer_models': relevance_result.get('printer_models', []),
                                'materials': relevance_result.get('materials', [])
                            })
                            logger.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {image_name} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ 3D-–ø–µ—á–∞—Ç–∏ (score={relevance_result.get('relevance_score', 0.5):.2f})")
                        else:
                            logger.info(f"‚ÑπÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {image_name} –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ 3D-–ø–µ—á–∞—Ç–∏")
                    
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {img_idx + 1}: {e}")
                    continue
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
            if relevant_images:
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –≤—Å–µ—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                all_problems = []
                all_solutions = []
                all_printer_models = set()
                all_materials = set()
                
                for img_data in relevant_images:
                    if img_data.get('problem_type'):
                        all_problems.append(img_data['problem_type'])
                    if img_data.get('printer_models'):
                        all_printer_models.update(img_data['printer_models'])
                    if img_data.get('materials'):
                        all_materials.update(img_data['materials'])
                
                return {
                    "problems_shown": list(set(all_problems)),
                    "solutions_shown": all_solutions,  # –ú–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –ª–æ–≥–∏–∫–æ–π –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–µ—à–µ–Ω–∏–π
                    "visual_indicators": [img['image_name'] for img in relevant_images],
                    "relevant_images_count": len(relevant_images),
                    "total_images_analyzed": len(images),
                    "printer_models": list(all_printer_models),
                    "materials": list(all_materials),
                    "image_analyses": relevant_images
                }
            else:
                logger.info("‚ÑπÔ∏è –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return None
                
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è VisionAnalyzer –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
            return await self._analyze_images_fallback(images)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ Gemini Vision: {e}")
            # Fallback –Ω–∞ –∞–Ω–∞–ª–∏–∑ –æ–ø–∏—Å–∞–Ω–∏–π
            return await self._analyze_images_fallback(images)
    
    async def _analyze_images_fallback(self, images: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """Fallback –º–µ—Ç–æ–¥: –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ –æ–ø–∏—Å–∞–Ω–∏—è–º (—Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥)"""
        image_descriptions = [img.get("description", "") or img.get("alt", "") for img in images]
        image_descriptions = [desc for desc in image_descriptions if desc]
        
        if not image_descriptions:
            return None
        
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ–ø–∏—Å–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ —Å—Ç–∞—Ç—å–∏ –æ 3D-–ø–µ—á–∞—Ç–∏.

–û–ü–ò–°–ê–ù–ò–Ø –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô:
{chr(10).join(f"- {desc}" for desc in image_descriptions[:10])}

–ó–ê–î–ê–ß–ê:
–û–ø—Ä–µ–¥–µ–ª–∏, –∫–∞–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –∏–ª–∏ —Ä–µ—à–µ–Ω–∏—è –ø–æ–∫–∞–∑–∞–Ω—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö.

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON:
{{
    "problems_shown": ["–ø—Ä–æ–±–ª–µ–º–∞1", "–ø—Ä–æ–±–ª–µ–º–∞2"] –∏–ª–∏ [],
    "solutions_shown": ["—Ä–µ—à–µ–Ω–∏–µ1"] –∏–ª–∏ [],
    "visual_indicators": ["–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä1"] –∏–ª–∏ []
}}
"""
        
        try:
            response = await self.llm_client.generate(
                prompt=prompt,
                system_prompt="–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ–ø–∏—Å–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON."
            )
            
            return self._extract_json(response)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (fallback): {e}")
        
        return None
    
    async def _create_summary(
        self,
        title: str,
        text_analysis: Dict[str, Any],
        image_analysis: Optional[Dict[str, Any]] = None,
        url: Optional[str] = None,
        content_type: str = "article"
    ) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –∏–∑–ª–æ–∂–µ–Ω–∏—è"""
        
        problem = text_analysis.get("problem", "")
        if image_analysis and image_analysis.get("problems_shown"):
            image_problems = ", ".join(image_analysis["problems_shown"])
            if image_problems:
                problem += f" (–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö –ø–æ–∫–∞–∑–∞–Ω–æ: {image_problems})"
        
        solutions = text_analysis.get("solutions", [])
        if image_analysis and image_analysis.get("solutions_shown"):
            for img_solution in image_analysis["solutions_shown"]:
                solutions.append({
                    "description": f"–ü–æ–∫–∞–∑–∞–Ω–æ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏: {img_solution}",
                    "parameters": {}
                })
        
        summary_text = f"""**–ü—Ä–æ–±–ª–µ–º–∞:** {problem}

**–°–∏–º–ø—Ç–æ–º—ã:**
{chr(10).join(f"- {s}" for s in text_analysis.get("symptoms", []))}

**–†–µ—à–µ–Ω–∏—è:**
{chr(10).join(f"- {sol.get('description', '')}" + (f" (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {sol.get('parameters', {})})" if sol.get('parameters') else "") for sol in solutions)}

**–ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã:**
{chr(10).join(f"- {kp}" for kp in text_analysis.get("key_points", []))}
"""
        
        return {
            "title": title,
            "url": url,
            "summary": summary_text,
            "problem": problem,
            "symptoms": text_analysis.get("symptoms", []),
            "solutions": solutions,
            "printer_models": text_analysis.get("printer_models", []),
            "materials": text_analysis.get("materials", []),
            "key_points": text_analysis.get("key_points", []),
            "image_analysis": image_analysis,
            "content_type": content_type
        }
    
    def _extract_simple_analysis(self, title: str, content: str) -> Dict[str, Any]:
        """–ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –±–µ–∑ LLM"""
        content_lower = content.lower()
        
        problem_keywords = {
            "stringing": ["stringing", "—Å–æ–ø–ª–∏", "–Ω–∏—Ç–æ—á–∫–∏"],
            "warping": ["warping", "–∫–æ—Ä–æ–±–ª–µ–Ω–∏–µ", "–æ—Ç—Å–ª–æ–µ–Ω–∏–µ"],
            "layer_separation": ["—Ä–∞—Å—Å–ª–æ–µ–Ω–∏–µ", "—Ç—Ä–µ—â–∏–Ω—ã", "—Å–ª–æ–∏"]
        }
        
        detected_problem = None
        for problem, keywords in problem_keywords.items():
            if any(kw in content_lower for kw in keywords):
                detected_problem = problem
                break
        
        return {
            "problem": detected_problem or "–ü—Ä–æ–±–ª–µ–º–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞",
            "symptoms": [],
            "solutions": [],
            "printer_models": [],
            "materials": [],
            "key_points": []
        }
    
    def _create_simple_summary(self, title: str, content: str, content_type: str = "article") -> Dict[str, Any]:
        """–ü—Ä–æ—Å—Ç–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞"""
        return {
            "title": title,
            "summary": f"**–î–æ–∫—É–º–µ–Ω—Ç:** {title}\n\n{content[:500]}...",
            "content_type": content_type,
            "problem": "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞",
            "symptoms": [],
            "solutions": [],
            "printer_models": [],
            "materials": [],
            "key_points": []
        }
