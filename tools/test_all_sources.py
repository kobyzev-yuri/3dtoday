#!/usr/bin/env python3
"""
–ü–æ–ª–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏–∑ image_urls.json
"""

import sys
import os
import json
import httpx
from pathlib import Path
from typing import Dict, Any, List
import time

sys.path.insert(0, str(Path(__file__).resolve().parents[1]))

API_BASE_URL = "http://localhost:8000"
TIMEOUT = 600


class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    MAGENTA = '\033[95m'
    END = '\033[0m'
    BOLD = '\033[1m'


def print_success(msg): print(f"{Colors.GREEN}‚úÖ {msg}{Colors.END}")
def print_error(msg): print(f"{Colors.RED}‚ùå {msg}{Colors.END}")
def print_info(msg): print(f"{Colors.BLUE}‚ÑπÔ∏è  {msg}{Colors.END}")
def print_warning(msg): print(f"{Colors.YELLOW}‚ö†Ô∏è  {msg}{Colors.END}")
def print_header(msg): print(f"\n{Colors.CYAN}{Colors.BOLD}{'='*70}{Colors.END}")
def print_header(msg): print(f"{Colors.CYAN}{Colors.BOLD}{msg}{Colors.END}")
def print_separator(): print(f"{Colors.CYAN}{'‚îÄ'*70}{Colors.END}")


def check_api():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ API"""
    try:
        resp = httpx.get(f"{API_BASE_URL}/health", timeout=10)
        if resp.status_code == 200:
            return True
        return False
    except Exception:
        return False


def test_url(url: str, problem_type: str, description: str, index: int, total: int) -> Dict[str, Any]:
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ URL"""
    print_separator()
    print_header(f"–¢–µ—Å—Ç {index}/{total}: {problem_type}")
    print_info(f"URL: {url}")
    print_info(f"–û–ø–∏—Å–∞–Ω–∏–µ: {description}")
    print_separator()
    
    result = {
        "url": url,
        "problem_type": problem_type,
        "description": description,
        "success": False,
        "error": None,
        "relevance_score": 0.0,
        "images_count": 0,
        "indexed_images": 0,
        "article_id": None
    }
    
    try:
        with httpx.Client(timeout=TIMEOUT) as client:
            # –®–ê–ì 1: –ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ –æ–±—ã—á–Ω—ã–π –º–µ—Ç–æ–¥ (parse) —Å –∞–Ω–∞–ª–∏–∑–æ–º —á–µ—Ä–µ–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä—è
            print_info("üìã –®–ê–ì 1: –ü–∞—Ä—Å–∏–Ω–≥ URL...")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π parse
            parse_response = client.post(
                f"{API_BASE_URL}/api/kb/articles/parse",
                json={
                    "source": url,
                    "source_type": "url",
                    "llm_provider": "gemini",
                    "model": "gemini-2.0-flash-exp"
                },
                timeout=TIMEOUT
            )
            
            if parse_response.status_code != 200:
                error_text = parse_response.text[:500] if len(parse_response.text) > 500 else parse_response.text
                result["error"] = f"HTTP {parse_response.status_code}: {error_text}"
                print_error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {result['error']}")
                return result
            
            parsed_data = parse_response.json()
            
            if not parsed_data.get("success"):
                result["error"] = parsed_data.get("error", "Unknown error")
                print_error(f"–ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è: {result['error']}")
                return result
            
            # –î–ª—è –æ–±—ã—á–Ω–æ–≥–æ parse —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
            doc_data = parsed_data.get("document", parsed_data.get("parsed_document", {}))
            review = parsed_data.get("review", {})
            
            # –ï—Å–ª–∏ review –Ω–µ—Ç –≤ –æ—Ç–≤–µ—Ç–µ, –∑–Ω–∞—á–∏—Ç –æ–Ω –±—ã–ª —Å–æ–∑–¥–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞—Ä–µ–º
            # –∏ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ parsed_data
            if not review and "review" not in parsed_data:
                # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ review –≤ –¥—Ä—É–≥–∏—Ö –ø–æ–ª—è—Ö
                review = parsed_data.get("analysis", {})
            
            # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ—Ç review, —Å–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π
            if not review:
                print_warning("Review –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ, —Å–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π...")
                review = {
                    "relevance_score": 0.7,  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö URL
                    "quality_score": 0.7,
                    "is_relevant": True,
                    "has_valuable_info": True,
                    "decision": "approve"
                }
            
            title = doc_data.get("title", "N/A")
            content = doc_data.get("content", "")
            images = doc_data.get("images", [])
            
            print_success(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ —É—Å–ø–µ—à–µ–Ω")
            print_info(f"   –ó–∞–≥–æ–ª–æ–≤–æ–∫: {title[:80]}")
            print_info(f"   –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
            print_info(f"   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑–≤–ª–µ—á–µ–Ω–æ: {len(images)}")
            
            result["images_count"] = len(images)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            relevance_score = review.get("relevance_score", 0.0)
            quality_score = review.get("quality_score", 0.0)
            is_relevant = review.get("is_relevant", False)
            decision = review.get("decision", "unknown")
            
            print_info(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:")
            print_info(f"   –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {relevance_score:.2f}")
            print_info(f"   –ö–∞—á–µ—Å—Ç–≤–æ: {quality_score:.2f}")
            print_info(f"   –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞: {'‚úÖ –î–∞' if is_relevant else '‚ùå –ù–µ—Ç'}")
            print_info(f"   –†–µ—à–µ–Ω–∏–µ: {decision}")
            
            result["relevance_score"] = relevance_score
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            if relevance_score < 0.6:
                result["error"] = f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å ({relevance_score:.2f}) –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞ (0.6)"
                print_warning(result["error"])
                return result
            
            if not is_relevant:
                result["error"] = "–î–æ–∫—É–º–µ–Ω—Ç –ø–æ–º–µ—á–µ–Ω –∫–∞–∫ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π"
                print_warning(result["error"])
                return result
            
            if decision == "reject":
                result["error"] = f"–î–æ–∫—É–º–µ–Ω—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω: {review.get('reason', 'N/A')[:100]}"
                print_warning(result["error"])
                return result
            
            # –®–ê–ì 2: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ KB
            print_info(f"\nüìã –®–ê–ì 2: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ KB...")
            add_response = client.post(
                f"{API_BASE_URL}/api/kb/articles/add_from_parse",
                json={
                    "parsed_document": doc_data,
                    "review": review,
                    "admin_decision": "approve",
                    "relevance_threshold": 0.6
                },
                timeout=TIMEOUT
            )
            
            if add_response.status_code != 200:
                error_text = add_response.text[:500] if len(add_response.text) > 500 else add_response.text
                result["error"] = f"HTTP {add_response.status_code} –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏: {error_text}"
                print_error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è: {result['error']}")
                return result
            
            add_result = add_response.json()
            
            if not add_result.get("success"):
                result["error"] = add_result.get("error", "Unknown error")
                print_error(f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å: {result['error']}")
                return result
            
            print_success("‚úÖ –°—Ç–∞—Ç—å—è —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ KB")
            
            article_id = add_result.get("article_id", "N/A")
            result["article_id"] = article_id
            print_info(f"   Article ID: {article_id}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            indexed_images = add_result.get("indexed_images", [])
            result["indexed_images"] = len(indexed_images)
            
            print_info(f"\nüì∑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")
            print_info(f"   –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(images)}")
            if indexed_images:
                print_success(f"   –ü—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ: {len(indexed_images)}")
                for idx, img_info in enumerate(indexed_images[:3], 1):
                    img_id = img_info.get("image_id", "N/A")
                    print_info(f"      {idx}. {img_id}")
            else:
                print_warning("   ‚ö†Ô∏è  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –±—ã–ª–∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω—ã")
            
            result["success"] = True
            print_success(f"\n‚úÖ –¢–µ—Å—Ç {index}/{total} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            
    except httpx.TimeoutException:
        result["error"] = f"–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ (>{TIMEOUT} —Å–µ–∫)"
        print_error(result["error"])
    except Exception as e:
        result["error"] = str(e)
        print_error(f"–û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
    
    return result


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print_header("="*70)
    print_header("üß™ –ü–û–õ–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ò–°–¢–û–ß–ù–ò–ö–û–í –ò–ó image_urls.json")
    print_header("="*70)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ API
    print_info("\nüìã –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ API...")
    if not check_api():
        print_error("‚ùå API —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –Ω–∞ http://localhost:8000")
        print_info("–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä: ./scripts/start_fastapi.sh")
        return 1
    
    print_success("‚úÖ API —Å–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ URL –∏–∑ image_urls.json
    project_root = Path(__file__).resolve().parents[1]
    urls_file = project_root / "knowledge_base" / "image_urls.json"
    
    if not urls_file.exists():
        print_error(f"‚ùå –§–∞–π–ª {urls_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return 1
    
    print_info(f"\nüìã –ó–∞–≥—Ä—É–∑–∫–∞ URL –∏–∑ {urls_file.name}...")
    
    with open(urls_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ URL
    test_urls = []
    
    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ (priority_high)
    if "priority_high" in data:
        for problem_type, articles in data["priority_high"].items():
            for article in articles:
                if article.get("has_images", False):
                    test_urls.append({
                        "url": article["url"],
                        "problem_type": article.get("problem_type", problem_type),
                        "description": article.get("description", "")
                    })
    
    # –°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç (priority_medium) - –±–µ—Ä–µ–º –ø–æ 1-2 –ø—Ä–∏–º–µ—Ä–∞
    if "priority_medium" in data:
        for problem_type, articles in data["priority_medium"].items():
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –ø—Ä–∏–º–µ—Ä –∏–∑ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            for article in articles[:1]:
                if article.get("has_images", False):
                    test_urls.append({
                        "url": article["url"],
                        "problem_type": article.get("problem_type", problem_type),
                        "description": article.get("description", "")
                    })
    
    if not test_urls:
        print_error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ URL –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        return 1
    
    print_success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(test_urls)} URL –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫
    print_info("\nüìã –°–ø–∏—Å–æ–∫ URL –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:")
    for i, item in enumerate(test_urls, 1):
        print_info(f"   {i}. [{item['problem_type']}] {item['url'][:70]}...")
    
    # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –µ—Å–ª–∏ AUTO_CONFIRM=1)
    auto_confirm = os.getenv("AUTO_CONFIRM", "0") == "1"
    
    if not auto_confirm:
        print("\n" + "="*70)
        try:
            response = input("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ? (y/n): ").strip().lower()
            if response != 'y':
                print_info("–û—Ç–º–µ–Ω–µ–Ω–æ")
                return 0
        except EOFError:
            # –ù–µ–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            print_info("–ù–µ–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏...")
    else:
        print_info("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º...")
    
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
    print_header("\n" + "="*70)
    print_header("üöÄ –ù–ê–ß–ê–õ–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
    print_header("="*70)
    
    results = []
    total = len(test_urls)
    
    for idx, item in enumerate(test_urls, 1):
        result = test_url(item["url"], item["problem_type"], item["description"], idx, total)
        results.append(result)
        
        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–µ—Å—Ç–∞–º–∏
        if idx < total:
            print_info(f"\n‚è≥ –ü–∞—É–∑–∞ 3 —Å–µ–∫—É–Ω–¥—ã –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º —Ç–µ—Å—Ç–æ–º...")
            time.sleep(3)
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print_header("\n" + "="*70)
    print_header("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print_header("="*70)
    
    successful = [r for r in results if r["success"]]
    failed = [r for r in results if not r["success"]]
    
    print_info(f"\n–í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {total}")
    print_success(f"–£—Å–ø–µ—à–Ω–æ: {len(successful)}")
    if failed:
        print_error(f"–ü—Ä–æ–≤–∞–ª–µ–Ω–æ: {len(failed)}")
    
    # –î–µ—Ç–∞–ª–∏ —É—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤
    if successful:
        print_header("\n‚úÖ –£—Å–ø–µ—à–Ω—ã–µ —Ç–µ—Å—Ç—ã:")
        total_images = sum(r["images_count"] for r in successful)
        total_indexed = sum(r["indexed_images"] for r in successful)
        avg_relevance = sum(r["relevance_score"] for r in successful) / len(successful)
        
        for r in successful:
            print_info(f"   ‚Ä¢ {r['problem_type']}: {r['article_id']}")
            print_info(f"     –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {r['relevance_score']:.2f}, "
                      f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {r['images_count']} (–ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ: {r['indexed_images']})")
        
        print_info(f"\n   –°—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {avg_relevance:.2f}")
        print_info(f"   –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {total_images} (–ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ: {total_indexed})")
    
    # –î–µ—Ç–∞–ª–∏ –ø—Ä–æ–≤–∞–ª–µ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤
    if failed:
        print_header("\n‚ùå –ü—Ä–æ–≤–∞–ª–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã:")
        for r in failed:
            print_error(f"   ‚Ä¢ {r['problem_type']}: {r['url'][:60]}...")
            print_error(f"     –û—à–∏–±–∫–∞: {r['error']}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results_file = project_root / "tools" / "test_results_all_sources.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump({
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total": total,
            "successful": len(successful),
            "failed": len(failed),
            "results": results
        }, f, ensure_ascii=False, indent=2)
    
    print_info(f"\nüìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {results_file}")
    
    return 0 if len(failed) == 0 else 1


if __name__ == "__main__":
    sys.exit(main())


